#!/usr/bin/env python3
"""
IPTV ç»„æ’­æå–å·¥å…· - ã€æ‰“å¼€é€Ÿåº¦ä¼˜å…ˆç‰ˆã€‘
ä¼˜å…ˆï¼šé¦–åŒ…å»¶è¿Ÿï¼ˆç§’å¼€ï¼‰ â†’ åˆ†è¾¨ç‡1080P+ â†’ ä¸‹è½½é€Ÿåº¦
"""

import asyncio
import os
import re
import sys
import time
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from urllib.parse import urljoin

import aiohttp
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

# å°è¯•å¯¼å…¥ tqdm è¿›åº¦æ¡åº“ï¼Œè‹¥å¤±è´¥åˆ™ä½¿ç”¨ç®€å•å›é€€
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    class tqdm:
        def __init__(self, *args, **kwargs):
            self.total = kwargs.get('total', 0)
            self.desc = kwargs.get('desc', '')
            self.unit = kwargs.get('unit', 'it')
            self.n = 0
        def update(self, n=1):
            self.n += n
        def close(self):
            print()
        def __enter__(self):
            return self
        def __exit__(self, *args):
            self.close()

# ============================================================================
# å…¨éƒ¨é…ç½®åŒºåŸŸï¼ˆåªæ”¹è¿™é‡Œï¼‰
# ============================================================================

# ---------------------------- åŸºç¡€è®¾ç½® ------------------------------------
TARGET_URL = os.getenv("TARGET_URL", "https://iptv.809899.xyz")
OUTPUT_DIR = Path(__file__).parent
MAX_IPS = int(os.getenv("MAX_IPS", "15"))
HEADLESS = os.getenv("HEADLESS", "true").lower() == "true"
BROWSER_TYPE = os.getenv("BROWSER_TYPE", "chromium")

# ------------------------ é¡µé¢åŠ è½½è¶…æ—¶ ------------------------------------
PAGE_LOAD_TIMEOUT = int(os.getenv("PAGE_LOAD_TIMEOUT", "60000"))

# ------------------------ é¡µé¢äº¤äº’é…ç½® ------------------------------------
PAGE_CONFIG = {
    "engine_search": ["å¼•ç´¢æœç´¢", "å¼•æ“æœç´¢", "å…³é”®è¯æœç´¢"],
    "multicast_tab": ["ç»„æ’­æå–"],
    "start_button": ["å¼€å§‹æ’­æ”¾", "å¼€å§‹æœç´¢", "å¼€å§‹æå–"],
}

# ------------------------ åˆ†ç±»è§„åˆ™é…ç½® ------------------------------------
CATEGORY_RULES = [
    {"name": "4Kä¸“åŒº",      "keywords": ["4k"]},
    {"name": "å¤®è§†é¢‘é“",    "keywords": ["cctv", "cetv", "ä¸­å¤®"]},
    {"name": "å«è§†é¢‘é“",    "keywords": ["å«è§†", "å‡¤å‡°", "tvb", "æ¹–å—", "æµ™æ±Ÿ", "æ±Ÿè‹", "ä¸œæ–¹",
                                      "åŒ—äº¬", "æ·±åœ³", "å±±ä¸œ", "å¤©æ´¥", "è´µå·", "å››å·", "é»‘é¾™æ±Ÿ",
                                      "å®‰å¾½", "æ±Ÿè¥¿", "æ¹–åŒ—", "ä¸œå—", "è¾½å®", "å¹¿ä¸œ", "æ²³åŒ—",
                                      "ç”˜è‚ƒ", "æ–°ç–†", "è¥¿è—", "å…µå›¢", "é‡åº†", "äº‘å—", "å¹¿è¥¿",
                                      "å±±è¥¿", "é™•è¥¿", "å‰æ—", "å†…è’™å¤", "æ²³å—", "å®å¤", "é’æµ·"]},
    {"name": "ç”µå½±é¢‘é“",    "keywords": ["ç”µå½±", "å½±è¿·", "å®¶åº­å½±é™¢", "åŠ¨ä½œç”µå½±", "å…‰å½±",
                                      "åŠ¨ä½œå½±é™¢", "å–œå‰§å½±é™¢", "ç»å…¸ç”µå½±", "çˆ±ç”µå½±", "chc"]},
    {"name": "è½®æ’­é¢‘é“",    "keywords": ["è½®æ’­é¢‘é“", "è½®æ’­"]},
    {"name": "å„¿ç«¥é¢‘é“",    "keywords": ["å°‘å„¿", "åŠ¨ç”»", "å¡é€š", "kids", "é‡‘é¹°å¡é€š",
                                      "å˜‰ä½³å¡é€š", "å¡é…·å°‘å„¿", "åŠ¨æ¼«ç§€åœº", "ä¼˜ä¼˜å®è´"]},
]

GROUP_ORDER = [
    "å¤®è§†é¢‘é“", "å«è§†é¢‘é“", "ç”µå½±é¢‘é“", "4Kä¸“åŒº", "å„¿ç«¥é¢‘é“", "è½®æ’­é¢‘é“"
]

# ------------------------ æ’­æ”¾åˆ—è¡¨ç”Ÿæˆè®¾ç½® --------------------------------
MAX_LINKS_PER_CHANNEL = int(os.getenv("MAX_LINKS_PER_CHANNEL", "5"))  # åªç•™æœ€å¿«5æ¡
OUTPUT_M3U_FILENAME = os.getenv("OUTPUT_M3U", "iptv_fast_channels.m3u")
OUTPUT_TXT_FILENAME = os.getenv("OUTPUT_TXT", "iptv_fast_channels.txt")

# -------------------------- åŠŸèƒ½å¼€å…³ -------------------------------------
ENABLE_CHINESE_CLEAN = True
ENABLE_DEDUPLICATION = True
ENABLE_SCREENSHOTS = False

# -------------------------- å¤®è§†é¢‘é“åç§°æ˜ å°„ -----------------------------
CCTV_USE_MAPPING = True
CCTV_NAME_MAPPING = {
    "1": "ç»¼åˆ", "2": "è´¢ç»", "3": "ç»¼è‰º", "4": "å›½é™…", "5": "ä½“è‚²",
    "5+": "ä½“è‚²èµ›äº‹", "6": "ç”µå½±", "7": "å›½é˜²å†›äº‹", "8": "ç”µè§†å‰§",
    "9": "çºªå½•", "10": "ç§‘æ•™", "11": "æˆæ›²", "12": "ç¤¾ä¼šä¸æ³•",
    "13": "æ–°é—»", "14": "å°‘å„¿", "15": "éŸ³ä¹", "16": "å¥¥æ—åŒ¹å…‹",
    "17": "å†œä¸šå†œæ‘",
}

# ====================== ã€æ‰“å¼€é€Ÿåº¦ä¼˜å…ˆã€‘æ ¸å¿ƒé…ç½® =======================
ENABLE_SPEED_TEST = True
SPEED_TEST_CONCURRENCY = 20
SPEED_TEST_TIMEOUT = 240

# é¦–åŒ…å»¶è¿Ÿï¼ˆæ‰“å¼€é€Ÿåº¦æ ¸å¿ƒï¼‰
FIRST_PACKET_TIMEOUT = 0.8  # è¶…è¿‡0.8ç§’ç›´æ¥ä¸¢

# é€Ÿåº¦é—¨æ§›
MIN_SPEED_FACTOR = 2.0

# åˆ†è¾¨ç‡å¿…é¡»1080P+
ENABLE_RESOLUTION_FILTER = True
MIN_RESOLUTION_WIDTH = 1920
MIN_RESOLUTION_HEIGHT = 1080
FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION = False

# ====================== è´Ÿè½½æ§åˆ¶ ======================
DELAY_BETWEEN_IPS = 2.0
DELAY_AFTER_CLICK = 0.5
MAX_CHANNELS_PER_IP = 0

# ====================== è„šæœ¬å…¨å±€è¶…æ—¶ ======================
SCRIPT_TIMEOUT = 3600

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

IP_PATTERN = re.compile(r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$')
CCTV_PATTERN = re.compile(r'(cctv)[-\s]?(\d{1,3})', re.IGNORECASE)
CETV_PATTERN = re.compile(r'(cetv)[-\s]?(\d)', re.IGNORECASE)
RESOLUTION_PATTERN = re.compile(r'(\d+)x(\d+)')
CHINESE_ONLY_PATTERN = re.compile(r'[^\u4e00-\u9fff]')

SCREENSHOT_DIR = OUTPUT_DIR / "debug_screenshots"
SCREENSHOT_DIR.mkdir(exist_ok=True)

def build_classifier():
    compiled = []
    for rule in CATEGORY_RULES:
        if not rule["keywords"]:
            continue
        pattern = re.compile("|".join(re.escape(kw.lower()) for kw in rule["keywords"]))
        compiled.append((rule["name"], pattern))
    return lambda name: next((group for group, pat in compiled if pat.search(name.lower())), None)

classify_channel = build_classifier()

def normalize_cctv(name: str) -> str:
    name_lower = name.lower()
    if "cctv5+" in name_lower or "cctv5ï¼‹" in name_lower or "cctv5åŠ " in name_lower:
        if CCTV_USE_MAPPING and "5+" in CCTV_NAME_MAPPING:
            return f"CCTV-5+{CCTV_NAME_MAPPING['5+']}"
        return "CCTV5+"
    cctv_match = CCTV_PATTERN.search(name_lower)
    if cctv_match:
        number = cctv_match.group(2)
        if CCTV_USE_MAPPING:
            suffix = CCTV_NAME_MAPPING.get(number, "")
            return f"CCTV-{number}{suffix}"
        rest = name[cctv_match.end():].strip()
        rest = re.sub(r'(?i)(HD|SD|é«˜æ¸…|æ ‡æ¸…|è¶…æ¸…|\s*-?\s*)?$', '', rest).strip()
        return f"CCTV-{number} {rest}".strip() if rest else f"CCTV-{number}"
    cetv_match = CETV_PATTERN.search(name_lower)
    if cetv_match:
        number = cetv_match.group(2)
        return f"CETV-{number}" if CCTV_USE_MAPPING else f"CETV{number}"
    return name

def clean_chinese_only(name: str) -> str:
    return CHINESE_ONLY_PATTERN.sub('', name)

def build_selector(text_list: list, element_type: str = "button") -> str:
    if not text_list:
        return ""
    if len(text_list) == 1:
        return f"{element_type}:has-text('{text_list[0]}')"
    pattern = "|".join(re.escape(t) for t in text_list)
    return f"{element_type}:text-matches('{pattern}')"

ENGINE_SELECTOR = build_selector(PAGE_CONFIG["engine_search"], "a.sidebar-link,button,div.segment-item")
MCAST_SELECTOR = build_selector(PAGE_CONFIG["multicast_tab"], "div.segment-item")
START_SELECTOR = build_selector(PAGE_CONFIG["start_button"], "button")

async def robust_click(locator, timeout=10000, description="å…ƒç´ "):
    try:
        await locator.scroll_into_view_if_needed(timeout=5000)
        await asyncio.sleep(0.2)
        await locator.click(force=True, timeout=timeout)
        return True
    except Exception:
        try:
            await locator.evaluate('el => el.scrollIntoViewIfNeeded()')
            await locator.evaluate('el => el.click()')
            return True
        except Exception:
            return False

# ====================== æµ‹é€Ÿæ ¸å¿ƒï¼šä¼˜å…ˆé¦–åŒ…å»¶è¿Ÿ =======================

async def fetch_url(session: aiohttp.ClientSession, url: str, timeout: int) -> Optional[bytes]:
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as resp:
            if resp.status == 200:
                return await resp.read()
    except Exception:
        pass
    return None

async def resolve_m3u8_playlist(session: aiohttp.ClientSession, url: str, timeout: int) -> Tuple[Optional[int], Optional[int], List[str]]:
    content = await fetch_url(session, url, timeout)
    if not content:
        return None, None, []
    lines = content.decode('utf-8', errors='ignore').splitlines()
    base_url = url[:url.rfind('/')+1] if '/' in url else url

    best_w, best_h = 0, 0
    best_uri = None
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXT-X-STREAM-INF:'):
            res_match = re.search(r'RESOLUTION=(\d+)x(\d+)', line)
            w, h = 0, 0
            if res_match:
                w, h = int(res_match.group(1)), int(res_match.group(2))
            if i+1 < len(lines):
                uri = lines[i+1].strip()
                if w * h > best_w * best_h:
                    best_w, best_h = w, h
                    best_uri = uri
            i += 2
        else:
            i += 1

    if best_uri:
        next_url = urljoin(base_url, best_uri)
        return await resolve_m3u8_playlist(session, next_url, timeout)

    ts_urls = []
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#'):
            ts_urls.append(urljoin(base_url, line))
    return best_w, best_h, ts_urls

async def test_speed_ts(url: str) -> Tuple[Optional[float], Optional[int], Optional[int]]:
    try:
        async with aiohttp.ClientSession() as session:
            width, height, ts_urls = await resolve_m3u8_playlist(session, url, 1)
            if not ts_urls:
                return None, None, None

            sample_urls = ts_urls[:2]
            total_bytes = 0
            total_time = 0.0
            for u in sample_urls:
                t0 = time.monotonic()
                data = await fetch_url(session, u, 1)
                used = time.monotonic() - t0
                if data:
                    total_bytes += len(data)
                    total_time += used
            if total_time <= 0 or total_bytes == 0:
                return None, None, None

            speed_mbps = (total_bytes / total_time) * 8 / 1_000_000
            return speed_mbps, width, height
    except Exception:
        return None, None, None

async def test_speed_fast(url: str, group: str, name: str, sem: asyncio.Semaphore) -> Optional[Tuple[str, str, str, float, float, bool]]:
    async with sem:
        try:
            # å…ˆæµ‹é¦–åŒ…
            t0 = time.monotonic()
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=2)) as session:
                async with session.head(url, allow_redirects=True):
                    pass
            latency = time.monotonic() - t0
            if latency > FIRST_PACKET_TIMEOUT:
                return None

            # å†æµ‹åˆ†è¾¨ç‡+é€Ÿåº¦
            is_m3u8 = url.lower().endswith(".m3u8")
            if not is_m3u8:
                return None

            speed, w, h = await test_speed_ts(url)
            if speed is None or speed < MIN_SPEED_FACTOR:
                return None

            res_ok = (w is not None and h is not None and
                      w >= MIN_RESOLUTION_WIDTH and h >= MIN_RESOLUTION_HEIGHT)
            if not res_ok:
                return None

            return (url, group, name, speed, latency, res_ok)
        except Exception:
            return None

async def run_speed_test(channel_urls: Dict[Tuple[str, str], List[str]]) -> Dict[Tuple[str, str], List[str]]:
    total = sum(len(v) for v in channel_urls.values())
    print(f"ğŸš€ å¼€å§‹æµ‹é€Ÿï¼ˆä¼˜å…ˆæ‰“å¼€é€Ÿåº¦ï¼‰ï¼Œå…± {total} æ¡é“¾æ¥")

    sem = asyncio.Semaphore(SPEED_TEST_CONCURRENCY)
    tasks = []
    for (g, n), urls in channel_urls.items():
        for u in urls:
            tasks.append(test_speed_fast(u, g, n, sem))

    results = []
    finished = 0
    printed = {10,20,30,40,50,60,70,80,90,100}
    progress_printed = set()

    for task in asyncio.as_completed(tasks):
        res = await task
        if res:
            results.append(res)
        finished += 1
        pct = int((finished / len(tasks)) * 100)
        for step in sorted(printed):
            if pct >= step and step not in progress_printed:
                print(f"æµ‹é€Ÿè¿›åº¦ï¼š{step}%")
                progress_printed.add(step)

    speed_map = defaultdict(list)
    for r in results:
        url, g, n, speed, lat, ok = r
        speed_map[(g, n)].append((url, speed, lat))

    out = defaultdict(list)
    for key, items in speed_map.items():
        # æ’åºï¼šå…ˆæŒ‰å»¶è¿Ÿå‡åºï¼Œå†æŒ‰é€Ÿåº¦é™åº
        items.sort(key=lambda x: (x[2], -x[1]))
        final = [u for u, s, lt in items[:MAX_LINKS_PER_CHANNEL]]
        out[key] = final

    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {sum(len(v) for v in out.values())} æ¡ä¼˜è´¨å¿«é“¾æ¥")
    return out

# ====================== é¡µé¢æå–é€»è¾‘ ===============================

async def extract_from_ip(page, row, ip_text: str) -> List[Tuple[str, str, str]]:
    entries = []
    print(f"\nğŸ“Œ å¤„ç† IP: {ip_text}")

    menu_btn = row.locator("button:has(i.fas.fa-list), button:has-text('â‰¡')").first
    if await menu_btn.count() > 0:
        await robust_click(menu_btn, description="èœå•")
    else:
        await row.locator("div.item-title").first.click(timeout=5000)
    await asyncio.sleep(DELAY_AFTER_CLICK)

    modal = page.locator(".modal-dialog").first
    try:
        await modal.wait_for(state="visible", timeout=8000)
    except PlaywrightTimeoutError:
        return entries

    items = modal.locator(".item-content")
    total = await items.count()
    limit = total if MAX_CHANNELS_PER_IP <= 0 else min(total, MAX_CHANNELS_PER_IP)

    for j in range(limit):
        item = items.nth(j)
        try:
            raw_name = await item.locator(".item-title").first.inner_text(timeout=3000)
            link = await item.locator(".item-subtitle").first.inner_text(timeout=3000)
        except:
            continue

        raw_name = raw_name.strip()
        link = link.strip()
        if not raw_name or not link:
            continue

        norm_name = normalize_cctv(raw_name)
        group = classify_channel(norm_name) or classify_channel(raw_name)
        if not group:
            continue

        final_name = norm_name if group == "å¤®è§†é¢‘é“" else (clean_chinese_only(raw_name) if ENABLE_CHINESE_CLEAN else raw_name)
        if not final_name:
            continue

        entries.append((group, final_name, link))
    return entries

async def wait_for_ip_elements(page):
    for attempt in range(2):
        print(f"â³ ç­‰å¾…IPæ•°æ® {attempt+1}/2")
        await asyncio.sleep(30)
        try:
            ok = await page.wait_for_function("""
                () => {
                    const es = document.querySelectorAll('div.item-title');
                    for(let e of es) if (e.innerText.match(/\\d+\\.\\d+\\.\\d+\\.\\d+/)) return true;
                    return false;
                }
            """, timeout=5000)
            if ok:
                print("âœ… IP æ•°æ®å·²åŠ è½½")
                return True
        except Exception:
            continue
    print("âš ï¸ ç»§ç»­æ‰§è¡Œ")
    return False

# ====================== ä¸»æµç¨‹ ===============================

async def _main():
    print(f"[{time.strftime('%H:%M:%S')}] ğŸš€ å¯åŠ¨ã€æ‰“å¼€é€Ÿåº¦ä¼˜å…ˆç‰ˆã€‘IPTVæå–")

    async with async_playwright() as p:
        browser = await getattr(p, BROWSER_TYPE).launch(headless=HEADLESS, args=["--no-sandbox"])
        context = await browser.new_context(viewport={"width": 1920, "height": 1080})
        page = await context.new_page()

        await page.goto(TARGET_URL, timeout=PAGE_LOAD_TIMEOUT, wait_until="networkidle")
        print("âœ… é¡µé¢åŠ è½½å®Œæˆ")

        if ENGINE_SELECTOR:
            el = page.locator(ENGINE_SELECTOR).first
            if await el.count() > 0:
                await robust_click(el, description="å¼•æ“æœç´¢")
                await asyncio.sleep(0.5)
                print("âœ… å·²ç‚¹å‡»å¼•æ“æœç´¢")

        if MCAST_SELECTOR:
            tab = page.locator(MCAST_SELECTOR).first
            await tab.wait_for(state="attached", timeout=15000)
            await robust_click(tab, description="ç»„æ’­æå–")
            await asyncio.sleep(0.5)
            print("âœ… å·²ç‚¹å‡»ç»„æ’­æå–")

        if START_SELECTOR:
            btn = page.locator(START_SELECTOR).first
            await robust_click(btn, description="å¼€å§‹æå–")
            await asyncio.sleep(0.5)
            print("âœ… å·²ç‚¹å‡»å¼€å§‹æå–")

        await wait_for_ip_elements(page)

        rows = page.locator("div.ios-list-item").filter(has_text="é¢‘é“:")
        total_ips = await rows.count()
        process_cnt = min(total_ips, MAX_IPS)
        print(f"ğŸ“‹ å…± {total_ips} ä¸ªIPï¼Œå¤„ç†å‰ {process_cnt} ä¸ª")

        raw = []
        for i in range(process_cnt):
            row = rows.nth(i)
            ip = await row.locator("div.item-title").first.inner_text()
            ip = ip.strip()
            if not IP_PATTERN.match(ip):
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆIP: {ip}")
                continue
            raw.extend(await extract_from_ip(page, row, ip))
            if i < process_cnt - 1:
                await asyncio.sleep(DELAY_BETWEEN_IPS)

        channel_map = defaultdict(list)
        seen = set()
        for g, n, u in raw:
            if ENABLE_DEDUPLICATION:
                key = (g, n, u)
                if key in seen:
                    continue
                seen.add(key)
            channel_map[(g, n)].append(u)

        print(f"ğŸ“Š å»é‡åï¼š{len(channel_map)} ä¸ªé¢‘é“ï¼Œ{sum(len(v) for v in channel_map.values())} æ¡é“¾æ¥")

        if ENABLE_SPEED_TEST and channel_map:
            channel_map = await run_speed_test(channel_map)

        final = []
        for (g, n), urls in channel_map.items():
            for u in urls:
                final.append((g, n, u))

        grouped = defaultdict(list)
        for g, n, u in final:
            grouped[g].append((n, u))

        cctv_g = next((g for g in grouped if "å¤®è§†" in g), None)
        if cctv_g:
            def ckey(x):
                m = re.search(r"CCTV-(\d+)", x[0])
                return int(m.group(1)) if m else 999
            grouped[cctv_g].sort(key=ckey)

        with open(OUTPUT_DIR / OUTPUT_M3U_FILENAME, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for g in GROUP_ORDER:
                for n, u in grouped.get(g, []):
                    f.write(f'#EXTINF:-1 group-title="{g}",{n}\n{u}\n')

        with open(OUTPUT_DIR / OUTPUT_TXT_FILENAME, "w", encoding="utf-8") as f:
            for g in GROUP_ORDER:
                if g not in grouped:
                    continue
                f.write(f"{g},#genre#\n")
                for n, u in grouped.get(g, []):
                    f.write(f"{n},{u}\n")
                f.write("\n")

        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼è¾“å‡ºï¼š")
        print(f"- {OUTPUT_M3U_FILENAME}")
        print(f"- {OUTPUT_TXT_FILENAME}")
        print(f"å…± {len(final)} æ¡ã€ç§’å¼€+1080P+ã€‘ä¼˜è´¨é“¾æ¥")

        await browser.close()

async def main_with_timeout():
    try:
        await asyncio.wait_for(_main(), timeout=SCRIPT_TIMEOUT)
    except asyncio.TimeoutError:
        print("âŒ è„šæœ¬è¶…æ—¶é€€å‡º")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main_with_timeout())
