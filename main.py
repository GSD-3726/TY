#!/usr/bin/env python3
"""
IPTV ÁªÑÊí≠ÊèêÂèñÂ∑•ÂÖ∑ - „ÄêÁßíÂºÄ‰ºòÂÖà + ÊµãÈÄüÁºìÂ≠òÁâà„Äë
‰ºòÂÖàÔºöÈ¶ñÂåÖÂª∂Ëøü ‚Üí 1080P+ ‚Üí ÁΩëÈÄü
Êñ∞Â¢ûÔºöÂ∑≤ÊµãÈÄüËøáÁöÑ‰ºòË¥®ÈìæÊé•Áõ¥Êé•Ë∑≥ËøáÔºå‰∏çÂÜçÈáçÂ§çÊµãÈÄü
"""

import asyncio
import os
import re
import sys
import time
import json
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from urllib.parse import urljoin

import aiohttp
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

# Â∞ùËØïÂØºÂÖ• tqdm
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    class tqdm:
        def __init__(self, *args, **kwargs): pass
        def update(self,n=1): pass
        def close(self): pass
        def __enter__(self): return self
        def __exit__(self,*args): self.close()

# ======================================================================================
# ================================== „ÄêÁΩÆÈ°∂ÂèØÊîπÂèÇÊï∞„Äë===================================
# üëá Âè™ÊîπËøôÈáåÔºåÂÖ∂‰ªñÂÖ®ÈÉ®Âà´Âä® üëá
# ======================================================================================

# 1. ÁõÆÊ†áÁΩëÁ´ô
TARGET_URL = "https://iptv.809899.xyz"

# 2. Êó†Â§¥Ê®°ÂºèÔºàÊúçÂä°Âô®/ÁõíÂ≠êÂøÖÈ°ª TrueÔºåÁîµËÑëÂèØ TrueÔºâ
HEADLESS = True

# 3. ‰∏ÄÊ¨°ÊäìÂ§öÂ∞ë‰∏™IPÔºàË∂äÂ§ßÊ∫êË∂äÂ§öÔºå‰ΩÜË∂äÊÖ¢Ôºâ
MAX_IPS = 20

# 4. „ÄêÊâìÂºÄÈÄüÂ∫¶Ê†∏ÂøÉ„ÄëÈ¶ñÂåÖË∂ÖÊó∂ÔºöË∂ÖËøáËøô‰∏™ÁßíÊï∞Áõ¥Êé•‰∏¢ÂºÉÔºàË∂äÂ∞èË∂ä‰∏•Ê†ºÔºâ
FIRST_PACKET_TIMEOUT = 2

# 5. ÊúÄÂ∞èÈÄüÂ∫¶ÔºàMbpsÔºâÔºö‰Ωé‰∫éËøô‰∏™ÈÄüÂ∫¶‰∏çË¶Å
MIN_SPEED_FACTOR = 2.0

# 6. ÂàÜËæ®ÁéáÔºöÂøÖÈ°ª 1080P+
ENABLE_RESOLUTION_FILTER = True
MIN_RESOLUTION_WIDTH  = 1920
MIN_RESOLUTION_HEIGHT = 1080

# 7. ÊØè‰∏™È¢ëÈÅì‰øùÁïôÊúÄÂø´Âá†Êù°ÔºàË∂äÂ∞ëË∂äÂø´ÔºåÂª∫ËÆÆ 3~5Ôºâ
MAX_LINKS_PER_CHANNEL = 5

# 8. ÊµãÈÄüÂπ∂ÂèëÔºöÁîµËÑëÂ∑ÆÂ∞±Êîπ 10
SPEED_TEST_CONCURRENCY = 20

# 9. ËæìÂá∫Êñá‰ª∂Âêç
OUTPUT_M3U_FILENAME = "iptv_fast_channels.m3u"
OUTPUT_TXT_FILENAME = "iptv_fast_channels.txt"

# 10. ÊµãÈÄüÁºìÂ≠òÔºàÂºÄÂêØÂêéÈáçÂ§çÈìæÊé•‰∏çÂÜçÊµãÈÄüÔºâ
ENABLE_SPEED_CACHE = True
CACHE_FILE = "speed_cache.json"

# ======================================================================================
# ================================== ‰ª•‰∏ã‰ª£Á†ÅËØ∑Âãø‰øÆÊîπ ================================
# ======================================================================================

PAGE_LOAD_TIMEOUT = 60000
DELAY_BETWEEN_IPS = 2.0
DELAY_AFTER_CLICK = 0.5
MAX_CHANNELS_PER_IP = 0
SCRIPT_TIMEOUT = 3600
ENABLE_SPEED_TEST = True
FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION = False
BROWSER_TYPE = "chromium"
OUTPUT_DIR = Path(__file__).parent
ENABLE_CHINESE_CLEAN = True
ENABLE_DEDUPLICATION = True
ENABLE_SCREENSHOTS = False
CCTV_USE_MAPPING = True

PAGE_CONFIG = {
    "engine_search": ["ÂºïÁ¥¢ÊêúÁ¥¢","ÂºïÊìéÊêúÁ¥¢","ÂÖ≥ÈîÆËØçÊêúÁ¥¢"],
    "multicast_tab": ["ÁªÑÊí≠ÊèêÂèñ"],
    "start_button": ["ÂºÄÂßãÊí≠Êîæ","ÂºÄÂßãÊêúÁ¥¢","ÂºÄÂßãÊèêÂèñ"],
}

CATEGORY_RULES = [
    {"name":"4K‰∏ìÂå∫","keywords":["4k"]},
    {"name":"Â§ÆËßÜÈ¢ëÈÅì","keywords":["cctv","cetv","‰∏≠Â§Æ"]},
    {"name":"Âç´ËßÜÈ¢ëÈÅì","keywords":["Âç´ËßÜ","Âá§Âá∞","tvb","ÊπñÂçó","ÊµôÊ±ü","Ê±üËãè","‰∏úÊñπ","Âåó‰∫¨","Ê∑±Âú≥","Â±±‰∏ú","Â§©Ê¥•","Ë¥µÂ∑û","ÂõõÂ∑ù","ÈªëÈæôÊ±ü","ÂÆâÂæΩ","Ê±üË•ø","ÊπñÂåó","‰∏úÂçó","ËæΩÂÆÅ","Âπø‰∏ú","Ê≤≥Âåó","ÁîòËÇÉ","Êñ∞ÁñÜ","Ë•øËóè","ÂÖµÂõ¢","ÈáçÂ∫Ü","‰∫ëÂçó","ÂπøË•ø","Â±±Ë•ø","ÈôïË•ø","ÂêâÊûó","ÂÜÖËíôÂè§","Ê≤≥Âçó","ÂÆÅÂ§è","ÈùíÊµ∑"]},
    {"name":"ÁîµÂΩ±È¢ëÈÅì","keywords":["ÁîµÂΩ±","ÂΩ±Ëø∑","ÂÆ∂Â∫≠ÂΩ±Èô¢","Âä®‰ΩúÁîµÂΩ±","ÂÖâÂΩ±","Âä®‰ΩúÂΩ±Èô¢","ÂñúÂâßÂΩ±Èô¢","ÁªèÂÖ∏ÁîµÂΩ±","Áà±ÁîµÂΩ±","chc"]},
    {"name":"ËΩÆÊí≠È¢ëÈÅì","keywords":["ËΩÆÊí≠È¢ëÈÅì","ËΩÆÊí≠"]},
    {"name":"ÂÑøÁ´•È¢ëÈÅì","keywords":["Â∞ëÂÑø","Âä®Áîª","Âç°ÈÄö","kids","ÈáëÈπ∞Âç°ÈÄö","Âòâ‰Ω≥Âç°ÈÄö","Âç°ÈÖ∑Â∞ëÂÑø","Âä®Êº´ÁßÄÂú∫","‰ºò‰ºòÂÆùË¥ù"]},
]

GROUP_ORDER = ["Â§ÆËßÜÈ¢ëÈÅì","Âç´ËßÜÈ¢ëÈÅì","ÁîµÂΩ±È¢ëÈÅì","4K‰∏ìÂå∫","ÂÑøÁ´•È¢ëÈÅì","ËΩÆÊí≠È¢ëÈÅì"]

CCTV_NAME_MAPPING = {
    "1":"ÁªºÂêà","2":"Ë¥¢Áªè","3":"ÁªºËâ∫","4":"ÂõΩÈôÖ","5":"‰ΩìËÇ≤",
    "5+":"‰ΩìËÇ≤Ëµõ‰∫ã","6":"ÁîµÂΩ±","7":"ÂõΩÈò≤ÂÜõ‰∫ã","8":"ÁîµËßÜÂâß",
    "9":"Á∫™ÂΩï","10":"ÁßëÊïô","11":"ÊàèÊõ≤","12":"Á§æ‰ºö‰∏éÊ≥ï",
    "13":"Êñ∞Èóª","14":"Â∞ëÂÑø","15":"Èü≥‰πê","16":"Â••ÊûóÂåπÂÖã","17":"ÂÜú‰∏öÂÜúÊùë"
}

IP_PATTERN = re.compile(r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$')
CCTV_PATTERN = re.compile(r'(cctv)[-\s]?(\d{1,3})', re.IGNORECASE)
CETV_PATTERN = re.compile(r'(cetv)[-\s]?(\d)', re.IGNORECASE)
CHINESE_ONLY_PATTERN = re.compile(r'[^\u4e00-\u9fff]')
SCREENSHOT_DIR = OUTPUT_DIR / "debug_screenshots"
SCREENSHOT_DIR.mkdir(exist_ok=True)

# ------------------------------
# ÁºìÂ≠òËØªÂÜô
# ------------------------------
def load_cache():
    if not ENABLE_SPEED_CACHE:
        return {}
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

def save_cache(cache):
    if not ENABLE_SPEED_CACHE:
        return
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except:
        pass

def build_classifier():
    compiled = []
    for rule in CATEGORY_RULES:
        if not rule["keywords"]: continue
        pattern = re.compile("|".join(re.escape(kw.lower()) for kw in rule["keywords"]))
        compiled.append((rule["name"], pattern))
    return lambda name: next((group for group, pat in compiled if pat.search(name.lower())), None)
classify_channel = build_classifier()

def normalize_cctv(name: str) -> str:
    name_lower = name.lower()
    if "cctv5+" in name_lower or "cctv5Ôºã" in name_lower or "cctv5Âä†" in name_lower:
        return f"CCTV-5+{CCTV_NAME_MAPPING['5+']}" if CCTV_USE_MAPPING else "CCTV5+"
    m = CCTV_PATTERN.search(name_lower)
    if m:
        num = m.group(2)
        return f"CCTV-{num}{CCTV_NAME_MAPPING.get(num,'')}" if CCTV_USE_MAPPING else f"CCTV-{num}"
    m = CETV_PATTERN.search(name_lower)
    if m:
        return f"CETV-{m.group(2)}" if CCTV_USE_MAPPING else f"CETV{m.group(2)}"
    return name

def clean_chinese_only(name: str) -> str:
    return CHINESE_ONLY_PATTERN.sub('', name)

def build_selector(text_list, element_type="button"):
    if not text_list: return ""
    if len(text_list)==1: return f"{element_type}:has-text('{text_list[0]}')"
    p = "|".join(re.escape(t) for t in text_list)
    return f"{element_type}:text-matches('{p}')"

ENGINE_SELECTOR = build_selector(PAGE_CONFIG["engine_search"], "a.sidebar-link,button,div.segment-item")
MCAST_SELECTOR  = build_selector(PAGE_CONFIG["multicast_tab"], "div.segment-item")
START_SELECTOR  = build_selector(PAGE_CONFIG["start_button"], "button")

async def robust_click(locator, timeout=10000):
    try:
        await locator.scroll_into_view_if_needed(timeout=5000)
        await asyncio.sleep(0.2)
        await locator.click(force=True, timeout=timeout)
        return True
    except:
        try:
            await locator.evaluate('el=>el.click()')
            return True
        except:
            return False

async def fetch_url(session, url, timeout):
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as r:
            if r.status==200: return await r.read()
    except: pass
    return None

async def resolve_m3u8_playlist(session, url, timeout):
    c = await fetch_url(session, url, timeout)
    if not c: return None,None,[]
    lines = c.decode('utf-8','ignore').splitlines()
    base = url[:url.rfind('/')+1] if '/' in url else url
    bw,bh,bu = 0,0,None
    i=0
    while i<len(lines):
        line = lines[i].strip()
        if line.startswith('#EXT-X-STREAM-INF:'):
            m = re.search(r'RESOLUTION=(\d+)x(\d+)', line)
            w,h = int(m.group(1)),int(m.group(2)) if m else (0,0)
            if i+1<len(lines):
                u = lines[i+1].strip()
                if w*h>bw*bh: bw,bh,bu=w,h,u
            i+=2
        else: i+=1
    if bu: return await resolve_m3u8_playlist(session, urljoin(base,bu), timeout)
    ts = [urljoin(base,l.strip()) for l in lines if l.strip() and not l.startswith('#')]
    return bw,bh,ts

async def test_speed_ts(url):
    try:
        async with aiohttp.ClientSession() as s:
            w,h,ts = await resolve_m3u8_playlist(s,url,1)
            if not ts: return None,None,None
            tb,tt = 0,0.0
            for u in ts[:2]:
                t0=time.monotonic()
                d=await fetch_url(s,u,1)
                e=time.monotonic()-t0
                if d: tb+=len(d); tt+=e
            if tt<=0 or tb==0: return None,None,None
            return (tb/tt)*8/1_000_000, w, h
    except: return None,None,None

async def test_speed_fast(url,g,n,sem):
    async with sem:
        try:
            t0=time.monotonic()
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=2)) as s:
                async with s.head(url,allow_redirects=True): pass
            lat=time.monotonic()-t0
            if lat>FIRST_PACKET_TIMEOUT: return None
            if not url.lower().endswith('.m3u8'): return None
            sp,ww,hh=await test_speed_ts(url)
            if sp is None or sp<MIN_SPEED_FACTOR: return None
            rok = ww and hh and ww>=MIN_RESOLUTION_WIDTH and hh>=MIN_RESOLUTION_HEIGHT
            if not rok: return None
            return url,g,n,sp,lat,rok
        except: return None

# ------------------------------
# Â∏¶ÁºìÂ≠òÁöÑÊµãÈÄüÂÖ•Âè£
# ------------------------------
async def run_speed_test(cm):
    cache = load_cache()
    total_links = sum(len(v) for v in cm.values())
    print(f"üöÄ ÂºÄÂßãÊµãÈÄüÔºàÂ∏¶ÁºìÂ≠òÔºâÔºåÊÄªËÆ° {total_links} Êù°ÈìæÊé•")

    need_test = []
    cached_ok = []

    for (g, n), urls in cm.items():
        for u in urls:
            key = u
            if key in cache:
                # ÁºìÂ≠òÈáåÊòØËææÊ†áÊâçÂ≠òÁöÑ
                cached_ok.append((u, g, n))
            else:
                need_test.append((u, g, n))

    print(f"üì¶ ÁºìÂ≠òÂëΩ‰∏≠Ôºö{len(cached_ok)} Êù°ÔºàË∑≥ËøáÊµãÈÄüÔºâ")
    print(f"‚ö° ÈúÄË¶ÅÊñ∞ÊµãÈÄüÔºö{len(need_test)} Êù°")

    # Êñ∞ÊµãÈÄü
    sem = asyncio.Semaphore(SPEED_TEST_CONCURRENCY)
    tasks = [test_speed_fast(u, g, n, sem) for u, g, n in need_test]
    new_ok = []
    finished = 0
    progress = set()

    for task in asyncio.as_completed(tasks):
        res = await task
        if res:
            new_ok.append(res)
        finished += 1
        pct = int(finished / len(tasks) * 100) if tasks else 100
        for s in [10,20,30,40,50,60,70,80,90,100]:
            if pct >= s and s not in progress:
                print(f"ÊµãÈÄüËøõÂ∫¶Ôºö{s}%")
                progress.add(s)

    # ÂÜôÂÖ•ÁºìÂ≠ò
    for r in new_ok:
        url, g, n, sp, lt, ok = r
        cache[url] = {
            "group": g,
            "name": n,
            "speed": round(sp, 2),
            "latency": round(lt, 3),
            "ts": time.time()
        }
    save_cache(cache)

    # ÂêàÂπ∂ÁªìÊûú
    all_items = []
    for u, g, n in cached_ok:
        # ‰ªéÁºìÂ≠òÂèñÈÄüÂ∫¶Áî®‰∫éÊéíÂ∫è
        sp = cache[u].get("speed", 99.9)
        lt = cache[u].get("latency", 0.1)
        all_items.append((u, g, n, sp, lt))
    for r in new_ok:
        u, g, n, sp, lt, _ = r
        all_items.append((u, g, n, sp, lt))

    # ÊåâÈ¢ëÈÅìÂàÜÁªÑ
    out = defaultdict(list)
    item_map = defaultdict(list)
    for u, g, n, sp, lt in all_items:
        item_map[(g, n)].append((u, sp, lt))

    for key, items in item_map.items():
        items.sort(key=lambda x: (x[2], -x[1]))
        out[key] = [u for u, _, _ in items[:MAX_LINKS_PER_CHANNEL]]

    total_out = sum(len(v) for v in out.values())
    print(f"‚úÖ ÊµãÈÄüÂÆåÊàêÔºåÊúÄÁªà‰øùÁïôÔºö{total_out} Êù°‰ºòË¥®ÁßíÂºÄÊ∫ê")
    return out

# ------------------------------
# È°µÈù¢ÊèêÂèñ
# ------------------------------
async def extract_from_ip(page,row,ip):
    e=[]
    print(f"\nüìå Â§ÑÁêÜIPÔºö{ip}")
    mb=row.locator("button:has(i.fas.fa-list),button:has-text('‚â°')").first
    if await mb.count()>0: await robust_click(mb)
    else: await row.locator("div.item-title").first.click(timeout=5000)
    await asyncio.sleep(DELAY_AFTER_CLICK)
    md=page.locator(".modal-dialog").first
    try: await md.wait_for(state="visible",timeout=8000)
    except: return e
    items=md.locator(".item-content")
    cnt=await items.count()
    lim=cnt if MAX_CHANNELS_PER_IP<=0 else min(cnt,MAX_CHANNELS_PER_IP)
    for i in range(lim):
        it=items.nth(i)
        try:
            na=await it.locator(".item-title").first.inner_text(timeout=3000)
            ur=await it.locator(".item-subtitle").first.inner_text(timeout=3000)
        except: continue
        na,ur=na.strip(),ur.strip()
        if not na or not ur: continue
        nna=normalize_cctv(na)
        gr=classify_channel(nna) or classify_channel(na)
        if not gr: continue
        fna=nna if gr=="Â§ÆËßÜÈ¢ëÈÅì" else (clean_chinese_only(na) if ENABLE_CHINESE_CLEAN else na)
        if not fna: continue
        e.append((gr,fna,ur))
    return e

async def wait_for_ip_elements(page):
    for _ in range(2):
        print("‚è≥ Á≠âÂæÖIPÊï∞ÊçÆ 30Áßí...")
        await asyncio.sleep(30)
        try:
            ok=await page.wait_for_function("""()=>{
                for(let e of document.querySelectorAll('div.item-title'))
                    if(/\\d+\\.\\d+\\.\\d+\\.\\d+/.test(e.innerText))return true;
                return false;
            }""",timeout=5000)
            if ok: print("‚úÖ IPÊï∞ÊçÆÂ∑≤Âä†ËΩΩ");return
        except:continue
    print("‚ö†Ô∏è Êú™Ëé∑ÂèñÂà∞IPÔºåÁªßÁª≠ÊâßË°å")

async def _main():
    print(f"[{time.strftime('%H:%M:%S')}] üöÄ ÂêØÂä®„ÄêÁßíÂºÄ‰ºòÂÖà+ÁºìÂ≠òÁâà„ÄëIPTVÊäìÂèñ")
    async with async_playwright() as p:
        b=await getattr(p,BROWSER_TYPE).launch(headless=HEADLESS,args=["--no-sandbox"])
        ctx=await b.new_context(viewport={"width":1920,"height":1080})
        page=await ctx.new_page()
        await page.goto(TARGET_URL,timeout=PAGE_LOAD_TIMEOUT,wait_until="networkidle")
        print("‚úÖ È°µÈù¢Âä†ËΩΩÂÆåÊàê")
        for sel,desc in [(ENGINE_SELECTOR,"ÂºïÊìéÊêúÁ¥¢"),(MCAST_SELECTOR,"ÁªÑÊí≠ÊèêÂèñ"),(START_SELECTOR,"ÂºÄÂßãÊèêÂèñ")]:
            e=page.locator(sel).first
            if await e.count()>0: await robust_click(e);await asyncio.sleep(0.5);print(f"‚úÖ {desc}")
        await wait_for_ip_elements(page)
        rows=page.locator("div.ios-list-item").filter(has_text="È¢ëÈÅì:")
        total=await rows.count()
        proc=min(total,MAX_IPS)
        print(f"üìã ÂÖ±{total}IPÔºåÂ§ÑÁêÜÂâç{proc}‰∏™")
        raw=[]
        for i in range(proc):
            r=rows.nth(i)
            ip=(await r.locator("div.item-title").first.inner_text()).strip()
            if not IP_PATTERN.match(ip): print(f"‚ö†Ô∏è Ë∑≥ËøáÊó†ÊïàIPÔºö{ip}");continue
            raw.extend(await extract_from_ip(page,r,ip))
            if i<proc-1: await asyncio.sleep(DELAY_BETWEEN_IPS)
        cm=defaultdict(list)
        seen=set()
        for g,n,u in raw:
            if ENABLE_DEDUPLICATION:
                k=(g,n,u)
                if k in seen:continue
                seen.add(k)
            cm[(g,n)].append(u)
        print(f"üìä ÂéªÈáçÂêéÔºö{len(cm)}È¢ëÈÅìÔºå{sum(len(v) for v in cm.values())}Êù°ÈìæÊé•")
        if ENABLE_SPEED_TEST and cm: cm=await run_speed_test(cm)
        final=[]
        for (g,n),us in cm.items():
            for u in us: final.append((g,n,u))
        grouped=defaultdict(list)
        for g,n,u in final: grouped[g].append((n,u))
        cg=next((g for g in grouped if "Â§ÆËßÜ" in g),None)
        if cg: grouped[cg].sort(key=lambda x:int(re.search(r"CCTV-(\d+)",x[0]).group(1)) if re.search(r"CCTV-(\d+)",x[0]) else 999)
        with open(OUTPUT_DIR/OUTPUT_M3U_FILENAME,'w',encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            for g in GROUP_ORDER:
                for n,u in grouped.get(g,[]):
                    f.write(f'#EXTINF:-1 group-title="{g}",{n}\n{u}\n')
        with open(OUTPUT_DIR/OUTPUT_TXT_FILENAME,'w',encoding='utf-8') as f:
            for g in GROUP_ORDER:
                if g not in grouped:continue
                f.write(f"{g},#genre#\n")
                for n,u in grouped[g]: f.write(f"{n},{u}\n")
                f.write("\n")
        print(f"\nüéâ ÂÖ®ÈÉ®ÂÆåÊàêÔºÅ")
        print(f"ËæìÂá∫Ôºö{OUTPUT_M3U_FILENAME} / {OUTPUT_TXT_FILENAME}")
        await b.close()

async def main_with_timeout():
    try: await asyncio.wait_for(_main(),SCRIPT_TIMEOUT)
    except asyncio.TimeoutError: print("‚ùå ËÑöÊú¨Ë∂ÖÊó∂");sys.exit(1)

if __name__=="__main__":
    asyncio.run(main_with_timeout())
