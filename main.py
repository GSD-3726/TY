#!/usr/bin/env python3
"""
IPTV ç»„æ’­æå–å·¥å…· - m3u8 åˆ†è¾¨ç‡+é€Ÿåº¦è¿‡æ»¤æ’åºå¢å¼ºç‰ˆ (HTTP æµ‹é€Ÿï¼Œå•ä½ Mbps)
"""

import asyncio
import os
import re
import sys
import time
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from urllib.parse import urljoin

import aiohttp
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

# å°è¯•å¯¼å…¥ tqdm è¿›åº¦æ¡åº“ï¼Œè‹¥å¤±è´¥åˆ™ä½¿ç”¨ç®€å•å›é€€
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    class tqdm:
        def __init__(self, *args, **kwargs):
            self.total = kwargs.get('total', 0)
            self.desc = kwargs.get('desc', '')
            self.unit = kwargs.get('unit', 'it')
            self.n = 0
        def update(self, n=1):
            self.n += n
        def close(self):
            print()
        def __enter__(self):
            return self
        def __exit__(self, *args):
            self.close()

# ============================================================================
# ======================== ã€ç½®é¡¶ï¼šå¸¸ç”¨éé¢‘é“é…ç½®ã€‘===========================
# ============================================================================

# ç½‘ç«™ä¸è¿è¡Œ
TARGET_URL              = "https://iptv.809899.xyz"    # ç›®æ ‡ç½‘ç«™
HEADLESS                = True                         # æ— å¤´æ¨¡å¼ï¼ˆæœåŠ¡å™¨å¿…å¼€ï¼‰
BROWSER_TYPE            = "chromium"                   # æµè§ˆå™¨ç±»å‹
MAX_IPS                 = 20                           # æœ€å¤šå¤„ç†å¤šå°‘ä¸ªIP
PAGE_LOAD_TIMEOUT       = 60000                        # é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰

# è¾“å‡ºæ–‡ä»¶
OUTPUT_M3U_FILENAME     = "iptv_channels.m3u"          # è¾“å‡ºm3uæ–‡ä»¶å
OUTPUT_TXT_FILENAME     = "iptv_channels.txt"          # è¾“å‡ºtxtæ–‡ä»¶å

# æµ‹é€Ÿæ€»å¼€å…³
ENABLE_SPEED_TEST       = True                         # æ˜¯å¦å¯ç”¨æµ‹é€Ÿ

# æµ‹é€Ÿå¹¶å‘ä¸è¶…æ—¶
SPEED_TEST_CONCURRENCY  = 15                        # åŒæ—¶æµ‹é€Ÿæ•°é‡
SPEED_TEST_TIMEOUT      = 2480                         # æµ‹é€Ÿæ•´ä½“è¶…æ—¶ï¼ˆç§’ï¼‰
SPEED_TEST_VERBOSE      = False                        # æ˜¯å¦æ‰“å°è¯¦ç»†é”™è¯¯

# æµ‹é€Ÿå‚æ•°
SPEED_TEST_DURATION     = 2                            # ém3u8ä¸‹è½½æµ‹é€Ÿæ—¶é•¿(ç§’)
TS_SAMPLE_COUNT         = 3                            # m3u8å–å‡ ä¸ªtsç‰‡æµ‹é€Ÿ
TS_DOWNLOAD_TIMEOUT     = 2                            # å•ä¸ªtsä¸‹è½½è¶…æ—¶(ç§’)

# é€Ÿåº¦è¿‡æ»¤ï¼ˆMbpsï¼‰
ENABLE_SPEED_FACTOR_FILTER = True                     # å¯ç”¨æœ€ä½é€Ÿåº¦é™åˆ¶
MIN_SPEED_FACTOR        = 1.5                          # æœ€å°é€Ÿåº¦è¦æ±‚

# åˆ†è¾¨ç‡è¿‡æ»¤
ENABLE_RESOLUTION_FILTER = True                        # å¯ç”¨åˆ†è¾¨ç‡è¿‡æ»¤
MIN_RESOLUTION_WIDTH    = 1920                         # æœ€å°å®½åº¦
MIN_RESOLUTION_HEIGHT   = 1080                         # æœ€å°é«˜åº¦
FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION = True            # æ— åˆ†è¾¨ç‡ä¿¡æ¯æ—¶æ˜¯å¦ä¿ç•™

# è´Ÿè½½ä¸ç­‰å¾…
DELAY_BETWEEN_IPS       = 3.0                          # å¤„ç†ä¸¤ä¸ªIPä¹‹é—´çš„å»¶è¿Ÿ
DELAY_AFTER_CLICK       = 0.5                          # ç‚¹å‡»åç­‰å¾…æ—¶é—´
MAX_CHANNELS_PER_IP     = 0                            # æ¯ä¸ªIPæœ€å¤šæå–é¢‘é“æ•°(0=ä¸é™)

# è„šæœ¬å…¨å±€è¶…æ—¶
SCRIPT_TIMEOUT          = 3000                         # è„šæœ¬æœ€å¤§è¿è¡Œæ—¶é—´(ç§’)

# åŠŸèƒ½å¼€å…³
ENABLE_CHINESE_CLEAN    = True                         # æ¸…ç†é¢‘é“åéä¸­æ–‡å­—ç¬¦
ENABLE_DEDUPLICATION    = True                         # é“¾æ¥å»é‡
ENABLE_SCREENSHOTS      = False                        # è°ƒè¯•æˆªå›¾

# å¤®è§†åç§°æ˜ å°„å¼€å…³
CCTV_USE_MAPPING        = True

# ============================================================================
# ============================ é¢‘é“åˆ†ç±»é…ç½®ï¼ˆä¸åŠ¨ï¼‰===========================
# ============================================================================

OUTPUT_DIR = Path(__file__).parent

PAGE_CONFIG = {
    "engine_search": ["å¼•ç´¢æœç´¢", "å¼•æ“æœç´¢", "å…³é”®è¯æœç´¢"],
    "multicast_tab": ["ç»„æ’­æå–"],
    "start_button": ["å¼€å§‹æ’­æ”¾", "å¼€å§‹æœç´¢", "å¼€å§‹æå–"],
}

CATEGORY_RULES = [
    {"name": "4Kä¸“åŒº",      "keywords": ["4k"]},
    {"name": "å¤®è§†é¢‘é“",    "keywords": ["cctv", "cetv", "ä¸­å¤®"]},
    {"name": "å«è§†é¢‘é“",    "keywords": ["å«è§†", "å‡¤å‡°", "tvb", "æ¹–å—", "æµ™æ±Ÿ", "æ±Ÿè‹", "ä¸œæ–¹",
                                      "åŒ—äº¬", "æ·±åœ³", "å±±ä¸œ", "å¤©æ´¥", "è´µå·", "å››å·", "é»‘é¾™æ±Ÿ",
                                      "å®‰å¾½", "æ±Ÿè¥¿", "æ¹–åŒ—", "ä¸œå—", "è¾½å®", "å¹¿ä¸œ", "æ²³åŒ—",
                                      "ç”˜è‚ƒ", "æ–°ç–†", "è¥¿è—", "å…µå›¢", "é‡åº†", "äº‘å—", "å¹¿è¥¿",
                                      "å±±è¥¿", "é™•è¥¿", "å‰æ—", "å†…è’™å¤", "æ²³å—", "å®å¤", "é’æµ·"]},
    {"name": "ç”µå½±é¢‘é“",    "keywords": ["ç”µå½±", "å½±è¿·", "å®¶åº­å½±é™¢", "åŠ¨ä½œç”µå½±", "å…‰å½±",
                                      "åŠ¨ä½œå½±é™¢", "å–œå‰§å½±é™¢", "ç»å…¸ç”µå½±", "çˆ±ç”µå½±", "chc"]},
    {"name": "è½®æ’­é¢‘é“",    "keywords": ["è½®æ’­é¢‘é“", "è½®æ’­"]},
    {"name": "å„¿ç«¥é¢‘é“",    "keywords": ["å°‘å„¿", "åŠ¨ç”»", "å¡é€š", "kids", "é‡‘é¹°å¡é€š",
                                      "å˜‰ä½³å¡é€š", "å¡é…·å°‘å„¿", "åŠ¨æ¼«ç§€åœº", "ä¼˜ä¼˜å®è´"]},
]

GROUP_ORDER = [
    "å¤®è§†é¢‘é“", "å«è§†é¢‘é“", "ç”µå½±é¢‘é“", "4Kä¸“åŒº", "å„¿ç«¥é¢‘é“", "è½®æ’­é¢‘é“"
]

CCTV_NAME_MAPPING = {
    "1": "ç»¼åˆ", "2": "è´¢ç»", "3": "ç»¼è‰º", "4": "å›½é™…", "5": "ä½“è‚²",
    "5+": "ä½“è‚²èµ›äº‹", "6": "ç”µå½±", "7": "å›½é˜²å†›äº‹", "8": "ç”µè§†å‰§",
    "9": "çºªå½•", "10": "ç§‘æ•™", "11": "æˆæ›²", "12": "ç¤¾ä¼šä¸æ³•",
    "13": "æ–°é—»", "14": "å°‘å„¿", "15": "éŸ³ä¹", "16": "å¥¥æ—åŒ¹å…‹",
    "17": "å†œä¸šå†œæ‘",
}

# ============================================================================
# æ ¸å¿ƒä»£ç ï¼ˆä»¥ä¸‹å…¨éƒ¨ä¸ç”¨æ”¹ï¼‰
# ============================================================================

IP_PATTERN = re.compile(r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$')
CCTV_PATTERN = re.compile(r'(cctv)[-\s]?(\d{1,3})', re.IGNORECASE)
CETV_PATTERN = re.compile(r'(cetv)[-\s]?(\d)', re.IGNORECASE)
RESOLUTION_PATTERN = re.compile(r'(\d+)x(\d+)')
CHINESE_ONLY_PATTERN = re.compile(r'[^\u4e00-\u9fff]')

SCREENSHOT_DIR = OUTPUT_DIR / "debug_screenshots"
SCREENSHOT_DIR.mkdir(exist_ok=True)

def build_classifier():
    compiled = []
    for rule in CATEGORY_RULES:
        if not rule["keywords"]:
            continue
        pattern = re.compile("|".join(re.escape(kw.lower()) for kw in rule["keywords"]))
        compiled.append((rule["name"], pattern))
    return lambda name: next((group for group, pat in compiled if pat.search(name.lower())), None)

classify_channel = build_classifier()

def normalize_cctv(name: str) -> str:
    name_lower = name.lower()
    if "cctv5+" in name_lower or "cctv5ï¼‹" in name_lower or "cctv5åŠ " in name_lower:
        if CCTV_USE_MAPPING and "5+" in CCTV_NAME_MAPPING:
            return f"CCTV-5+{CCTV_NAME_MAPPING['5+']}"
        return "CCTV5+"
    cctv_match = CCTV_PATTERN.search(name_lower)
    if cctv_match:
        number = cctv_match.group(2)
        if CCTV_USE_MAPPING:
            suffix = CCTV_NAME_MAPPING.get(number, "")
            return f"CCTV-{number}{suffix}"
        rest = name[cctv_match.end():].strip()
        rest = re.sub(r'(?i)(HD|SD|é«˜æ¸…|æ ‡æ¸…|è¶…æ¸…|\s*-?\s*)?$', '', rest).strip()
        return f"CCTV-{number} {rest}".strip() if rest else f"CCTV-{number}"
    cetv_match = CETV_PATTERN.search(name_lower)
    if cetv_match:
        number = cetv_match.group(2)
        return f"CETV-{number}" if CCTV_USE_MAPPING else f"CETV{number}"
    return name

def clean_chinese_only(name: str) -> str:
    return CHINESE_ONLY_PATTERN.sub('', name)

def build_selector(text_list: list, element_type: str = "button") -> str:
    if not text_list:
        return ""
    if len(text_list) == 1:
        return f"{element_type}:has-text('{text_list[0]}')"
    pattern = "|".join(re.escape(t) for t in text_list)
    return f"{element_type}:text-matches('{pattern}')"

ENGINE_SELECTOR = build_selector(PAGE_CONFIG["engine_search"], "a.sidebar-link,button,div.segment-item")
MCAST_SELECTOR = build_selector(PAGE_CONFIG["multicast_tab"], "div.segment-item")
START_SELECTOR = build_selector(PAGE_CONFIG["start_button"], "button")

async def robust_click(locator, timeout=10000, description="å…ƒç´ "):
    try:
        await locator.scroll_into_view_if_needed(timeout=5000)
        await asyncio.sleep(0.2)
        await locator.click(force=True, timeout=timeout)
        return True
    except Exception:
        try:
            await locator.evaluate('el => el.scrollIntoViewIfNeeded()')
            await locator.evaluate('el => el.click()')
            return True
        except Exception:
            return False

# ====================== çº¯ HTTP æµ‹é€Ÿå‡½æ•° =======================

async def fetch_url(session: aiohttp.ClientSession, url: str, timeout: int) -> Optional[bytes]:
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as resp:
            if resp.status == 200:
                return await resp.read()
    except Exception:
        pass
    return None

async def resolve_m3u8_playlist(session: aiohttp.ClientSession, url: str, timeout: int) -> Tuple[Optional[int], Optional[int], List[str]]:
    content = await fetch_url(session, url, timeout)
    if not content:
        return None, None, []
    lines = content.decode('utf-8', errors='ignore').splitlines()
    base_url = url[:url.rfind('/')+1] if '/' in url else url

    best_w, best_h = 0, 0
    best_uri = None
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXT-X-STREAM-INF:'):
            res_match = re.search(r'RESOLUTION=(\d+)x(\d+)', line)
            w, h = 0, 0
            if res_match:
                w, h = int(res_match.group(1)), int(res_match.group(2))
            if i+1 < len(lines):
                uri = lines[i+1].strip()
                if w * h > best_w * best_h:
                    best_w, best_h = w, h
                    best_uri = uri
            i += 2
        else:
            i += 1

    if best_uri:
        next_url = urljoin(base_url, best_uri)
        return await resolve_m3u8_playlist(session, next_url, timeout)

    ts_urls = []
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#'):
            ts_urls.append(urljoin(base_url, line))
    return best_w, best_h, ts_urls

async def test_speed_ts(url: str) -> Tuple[Optional[float], Optional[int], Optional[int]]:
    try:
        async with aiohttp.ClientSession() as session:
            width, height, ts_urls = await resolve_m3u8_playlist(session, url, TS_DOWNLOAD_TIMEOUT)
            if not ts_urls:
                return None, None, None

            sample_urls = ts_urls[:TS_SAMPLE_COUNT]
            if not sample_urls:
                return None, None, None

            total_bytes = 0
            total_time = 0.0
            for u in sample_urls:
                start = time.monotonic()
                data = await fetch_url(session, u, TS_DOWNLOAD_TIMEOUT)
                elapsed = time.monotonic() - start
                if data and elapsed > 0:
                    total_bytes += len(data)
                    total_time += elapsed
            if total_time == 0 or total_bytes == 0:
                return None, None, None

            speed_mbps = (total_bytes / total_time) * 8 / 1_000_000
            return speed_mbps, width, height
    except Exception:
        return None, None, None

async def test_speed_direct(url: str, duration: int) -> Optional[float]:
    try:
        async with aiohttp.ClientSession() as session:
            start = time.monotonic()
            total_bytes = 0
            timeout = aiohttp.ClientTimeout(total=duration + 2)
            async with session.get(url, timeout=timeout) as resp:
                if resp.status != 200:
                    return None
                while True:
                    chunk = await resp.content.read(8192)
                    if not chunk:
                        break
                    total_bytes += len(chunk)
                    elapsed = time.monotonic() - start
                    if elapsed >= duration:
                        break
            elapsed = time.monotonic() - start
            if elapsed <= 0 or total_bytes == 0:
                return None
            speed_mbps = (total_bytes / elapsed) * 8 / 1_000_000
            return speed_mbps
    except Exception:
        return None

async def test_speed(url: str, group: str, name: str, semaphore: asyncio.Semaphore) -> Optional[Tuple[str, str, str, float, bool]]:
    async with semaphore:
        is_m3u8 = url.lower().endswith(".m3u8") or "m3u8" in url.lower()

        if is_m3u8:
            speed_mbps, width, height = await test_speed_ts(url)
            if speed_mbps is None:
                return None
            if ENABLE_SPEED_FACTOR_FILTER and speed_mbps < MIN_SPEED_FACTOR:
                return None
            resolution_ok = True
            if ENABLE_RESOLUTION_FILTER:
                if width is None or height is None:
                    resolution_ok = FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION
                else:
                    resolution_ok = (width >= MIN_RESOLUTION_WIDTH and height >= MIN_RESOLUTION_HEIGHT)
            return (url, group, name, speed_mbps, resolution_ok)
        else:
            speed_mbps = await test_speed_direct(url, SPEED_TEST_DURATION)
            if speed_mbps is None:
                return None
            if ENABLE_SPEED_FACTOR_FILTER and speed_mbps < MIN_SPEED_FACTOR:
                return None
            resolution_ok = FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION if ENABLE_RESOLUTION_FILTER else True
            return (url, group, name, speed_mbps, resolution_ok)

# ====================== ã€ç®€åŒ–ï¼šåªè¾“å‡º 10% 20% 30%...100%ã€‘=======================
async def run_speed_test(channel_urls: Dict[Tuple[str, str], List[str]]) -> Dict[Tuple[str, str], List[str]]:
    total = sum(len(v) for v in channel_urls.values())
    print(f"ğŸš€ å¼€å§‹æµ‹é€Ÿï¼Œå…± {total} æ¡é“¾æ¥")

    sem = asyncio.Semaphore(SPEED_TEST_CONCURRENCY)
    tasks = []
    for (g, n), urls in channel_urls.items():
        for u in urls:
            tasks.append(test_speed(u, g, n, sem))

    results = []
    finished = 0
    printed = set()

    for task in asyncio.as_completed(tasks):
        res = await task
        if res:
            results.append(res)
        finished += 1

        pct = (finished / len(tasks)) * 100
        for step in [10,20,30,40,50,60,70,80,90,100]:
            if pct >= step and step not in printed:
                print(f"æµ‹é€Ÿè¿›åº¦ï¼š{step}%")
                printed.add(step)

    speed_map = defaultdict(list)
    for r in results:
        url, g, n, s, ok_res = r
        speed_map[(g, n)].append((url, s, ok_res))

    out = defaultdict(list)
    for key, items in speed_map.items():
        items.sort(key=lambda x: x[1], reverse=True)
        qualified = [u for u, s, ok in items if ok]
        if qualified:
            final = qualified[:MAX_LINKS_PER_CHANNEL]
        else:
            final = [u for u, s, ok in items][:MAX_LINKS_PER_CHANNEL]
        out[key] = final

    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {sum(len(v) for v in out.values())} æ¡æœ‰æ•ˆé“¾æ¥")
    return out

# ====================== IP æå–é€»è¾‘ ===============================

async def extract_from_ip(page, row, ip_text: str) -> List[Tuple[str, str, str]]:
    entries = []
    print(f"\nğŸ“Œ å¤„ç† IP: {ip_text}")

    menu_btn = row.locator("button:has(i.fas.fa-list), button:has-text('â‰¡'), button:has(i.fa-list)").first
    if await menu_btn.count() > 0:
        await robust_click(menu_btn, description="èœå•æŒ‰é’®")
    else:
        await row.locator("div.item-title").first.click(timeout=5000)
    await asyncio.sleep(DELAY_AFTER_CLICK)

    modal = page.locator(".modal-dialog").first
    try:
        await modal.wait_for(state="visible", timeout=8000)
    except PlaywrightTimeoutError:
        return entries

    items = modal.locator(".item-content")
    total = await items.count()
    limit = total if MAX_CHANNELS_PER_IP <= 0 else min(total, MAX_CHANNELS_PER_IP)

    for j in range(limit):
        item = items.nth(j)
        try:
            raw_name = await item.locator(".item-title").first.inner_text(timeout=5000)
            link = await item.locator(".item-subtitle").first.inner_text(timeout=5000)
        except:
            continue

        raw_name = raw_name.strip()
        link = link.strip()
        if not raw_name or not link:
            continue

        norm_name = normalize_cctv(raw_name)
        group = classify_channel(norm_name) or classify_channel(raw_name)
        if not group:
            continue

        final_name = norm_name if group == "å¤®è§†é¢‘é“" else (clean_chinese_only(raw_name) if ENABLE_CHINESE_CLEAN else raw_name)
        if not final_name:
            continue

        entries.append((group, final_name, link))
    return entries

# ====================== ç­‰å¾… IPï¼šç‚¹å‡»åç­‰30ç§’ï¼Œæ²¡æ•°æ®å†ç­‰30ç§’ ======================
async def wait_for_ip_elements(page, max_retries=2):
    for attempt in range(2):
        print(f"â³ ç¬¬ {attempt+1} æ¬¡ç­‰å¾…ï¼š30 ç§’åè·å–æ•°æ®")
        await asyncio.sleep(30)
        
        try:
            ok = await page.wait_for_function("""
                () => {
                    const elements = document.querySelectorAll('div.item-title');
                    for (let el of elements) {
                        if (el.innerText.match(/\\d+\\.\\d+\\.\\d+\\.\\d+/)) return true;
                    }
                    return false;
                }
            """, timeout=5000)
            if ok:
                print("âœ… IP æ•°æ®å·²åŠ è½½")
                return True
        except Exception:
            print(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡æœªè·å–åˆ°æ•°æ®")
    print("âŒ ä¸¤æ¬¡ç­‰å¾…åä»æ— æ•°æ®ï¼Œç»§ç»­æ‰§è¡Œ")
    return False

# ====================== ä¸»æµç¨‹ ===============================

async def _main():
    global ENABLE_SPEED_TEST
    print(f"[{time.strftime('%H:%M:%S')}] ğŸš€ è„šæœ¬å¼€å§‹")

    try:
        import aiohttp
    except ImportError:
        print("âŒ è¯·å®‰è£… aiohttp: pip install aiohttp")
        sys.exit(1)

    async with async_playwright() as p:
        browser = await getattr(p, BROWSER_TYPE).launch(headless=HEADLESS, args=["--no-sandbox"])
        context = await browser.new_context(viewport={"width": 1920, "height": 1080})
        page = await context.new_page()

        await page.goto(TARGET_URL, timeout=PAGE_LOAD_TIMEOUT, wait_until="networkidle")
        print("âœ… é¡µé¢åŠ è½½å®Œæˆ")

        if ENGINE_SELECTOR:
            elem = page.locator(ENGINE_SELECTOR).first
            if await elem.count() > 0:
                await robust_click(elem, description="å¼•æ“æœç´¢")
                await asyncio.sleep(DELAY_AFTER_CLICK)
                print("âœ… ç‚¹å‡»å¼•æ“æœç´¢")

        if MCAST_SELECTOR:
            tab = page.locator(MCAST_SELECTOR).first
            await tab.wait_for(state="attached", timeout=15000)
            await robust_click(tab, description="ç»„æ’­æå–")
            await asyncio.sleep(DELAY_AFTER_CLICK)
            print("âœ… ç‚¹å‡»ç»„æ’­æå–")

        if START_SELECTOR:
            btn = page.locator(START_SELECTOR).first
            await robust_click(btn, description="å¼€å§‹æå–")
            await asyncio.sleep(DELAY_AFTER_CLICK)
            print("âœ… ç‚¹å‡»å¼€å§‹æå–")

        print("â³ ç­‰å¾…æ•°æ®åŠ è½½ï¼ˆ30s + 30sï¼‰...")
        await wait_for_ip_elements(page)

        rows = page.locator("div.ios-list-item").filter(has_text="é¢‘é“:")
        total_ips = await rows.count()
        process_cnt = min(total_ips, MAX_IPS) if MAX_IPS else total_ips
        print(f"ğŸ“‹ å…± {total_ips} ä¸ªIPï¼Œå¤„ç†å‰ {process_cnt} ä¸ª")

        raw = []
        for i in range(process_cnt):
            row = rows.nth(i)
            ip = await row.locator("div.item-title").first.inner_text()
            ip = ip.strip()
            if not IP_PATTERN.match(ip):
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆ IP: {ip}")
                continue
            raw.extend(await extract_from_ip(page, row, ip))
            if i < process_cnt - 1:
                await asyncio.sleep(DELAY_BETWEEN_IPS)

        channel_map = defaultdict(list)
        seen = set()
        for g, n, u in raw:
            if ENABLE_DEDUPLICATION:
                k = (g, n, u)
                if k in seen:
                    continue
                seen.add(k)
            channel_map[(g, n)].append(u)

        print(f"ğŸ“Š å»é‡åï¼š{len(channel_map)} ä¸ªé¢‘é“ï¼Œ{sum(len(v) for v in channel_map.values())} æ¡é“¾æ¥")

        if ENABLE_SPEED_TEST and channel_map:
            channel_map = await run_speed_test(channel_map)

        final = []
        for (g, n), urls in channel_map.items():
            for u in urls:
                final.append((g, n, u))

        grouped = defaultdict(list)
        for g, n, u in final:
            grouped[g].append((n, u))

        cctv_g = next((g for g in grouped if "å¤®è§†" in g), None)
        if cctv_g:
            def ckey(x):
                m = re.search(r"CCTV-(\d+)", x[0])
                return int(m.group(1)) if m else 999
            grouped[cctv_g].sort(key=ckey)

        with open(OUTPUT_DIR / OUTPUT_M3U_FILENAME, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            for g in GROUP_ORDER:
                for n, u in grouped.get(g, []):
                    f.write(f'#EXTINF:-1 group-title="{g}",{n}\n{u}\n')

        with open(OUTPUT_DIR / OUTPUT_TXT_FILENAME, "w", encoding="utf-8") as f:
            for g in GROUP_ORDER:
                if g not in grouped:
                    continue
                f.write(f"{g},#genre#\n")
                for n, u in grouped.get(g, []):
                    f.write(f"{n},{u}\n")
                f.write("\n")

        print(f"\nğŸ‰ å®Œæˆï¼å…±å¯¼å‡º {len(final)} æ¡æœ‰æ•ˆé“¾æ¥")
        await browser.close()

async def main_with_timeout():
    try:
        await asyncio.wait_for(_main(), timeout=SCRIPT_TIMEOUT)
    except asyncio.TimeoutError:
        print("âŒ è„šæœ¬æ•´ä½“è¶…æ—¶é€€å‡º")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main_with_timeout())
