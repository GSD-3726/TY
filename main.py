#!/usr/bin/env python3
"""
IPTV ç»„æ’­æå–å·¥å…· - 3TSåˆ†ç‰‡ç²¾å‡†æµ‹é€Ÿç‰ˆï¼ˆä¸šå†…æœ€å‡†ï¼‰
"""

import asyncio
import os
import re
import shutil
import sys
import time
import aiohttp
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from urllib.parse import urljoin

from playwright.async_api import async_playwright
from playwright.async_api import TimeoutError as PlaywrightTimeoutError

# ============================================================================
# å…¨éƒ¨é…ç½®åŒºåŸŸï¼ˆåªæ”¹è¿™é‡Œï¼‰
# ============================================================================

# ---------------------------- åŸºç¡€è®¾ç½® ------------------------------------
TARGET_URL = os.getenv("TARGET_URL", "https://iptv.809899.xyz")
OUTPUT_DIR = Path(__file__).parent
MAX_IPS = int(os.getenv("MAX_IPS", "5"))
HEADLESS = True  # GitHub å¿…é¡» True

# ------------------------ é¡µé¢åŠ è½½è¶…æ—¶ ------------------------------------
PAGE_LOAD_TIMEOUT = 120000
ACTION_WAIT_TIMEOUT = 10000

# ------------------------ é¡µé¢äº¤äº’é…ç½® ------------------------------------
PAGE_CONFIG = {
    "engine_search": ["å¼•ç´¢æœç´¢", "å¼•æ“æœç´¢", "å…³é”®è¯æœç´¢"],
    "multicast_tab": ["ç»„æ’­æå–"],
    "start_button": ["å¼€å§‹æ’­æ”¾", "å¼€å§‹æœç´¢", "å¼€å§‹æå–"],
}

# ------------------------ åˆ†ç±»è§„åˆ™é…ç½® ------------------------------------
CATEGORY_RULES = [
    {"name": "4Kä¸“åŒº",      "keywords": ["4k"]},
    {"name": "å¤®è§†é¢‘é“",    "keywords": ["cctv", "cetv", "ä¸­å¤®"]},
    {"name": "å«è§†é¢‘é“",    "keywords": ["å«è§†", "å‡¤å‡°", "tvb", "æ¹–å—", "æµ™æ±Ÿ", "æ±Ÿè‹", "ä¸œæ–¹",
                                      "åŒ—äº¬", "æ·±åœ³", "å±±ä¸œ", "å¤©æ´¥", "è´µå·", "å››å·", "é»‘é¾™æ±Ÿ",
                                      "å®‰å¾½", "æ±Ÿè¥¿", "æ¹–åŒ—", "ä¸œå—", "è¾½å®", "å¹¿ä¸œ", "æ²³åŒ—",
                                      "ç”˜è‚ƒ", "æ–°ç–†", "è¥¿è—", "å…µå›¢", "é‡åº†", "äº‘å—", "å¹¿è¥¿",
                                      "å±±è¥¿", "é™•è¥¿", "å‰æ—", "å†…è’™å¤", "æ²³å—", "å®å¤", "é’æµ·"]},
    {"name": "ç”µå½±é¢‘é“",    "keywords": ["ç”µå½±", "å½±è¿·", "å®¶åº­å½±é™¢", "åŠ¨ä½œç”µå½±", "å…‰å½±",
                                      "åŠ¨ä½œå½±é™¢", "å–œå‰§å½±é™¢", "ç»å…¸ç”µå½±", "çˆ±ç”µå½±", "chc"]},
    {"name": "è½®æ’­é¢‘é“",    "keywords": ["è½®æ’­é¢‘é“", "è½®æ’­"]},
    {"name": "å„¿ç«¥é¢‘é“",    "keywords": ["å°‘å„¿", "åŠ¨ç”»", "å¡é€š", "kids", "é‡‘é¹°å¡é€š",
                                      "å˜‰ä½³å¡é€š", "å¡é…·å°‘å„¿", "åŠ¨æ¼«ç§€åœº", "ä¼˜ä¼˜å®è´"]},
]

GROUP_ORDER = [
    "å¤®è§†é¢‘é“", "å«è§†é¢‘é“", "ç”µå½±é¢‘é“", "4Kä¸“åŒº", "å„¿ç«¥é¢‘é“", "è½®æ’­é¢‘é“"
]

# ------------------------ æ’­æ”¾åˆ—è¡¨ç”Ÿæˆè®¾ç½® --------------------------------
MAX_LINKS_PER_CHANNEL = int(os.getenv("MAX_LINKS_PER_CHANNEL", "10"))
OUTPUT_M3U_FILENAME = "iptv_channels.m3u"
OUTPUT_TXT_FILENAME = "iptv_channels.txt"

# -------------------------- åŠŸèƒ½å¼€å…³ -------------------------------------
ENABLE_CHINESE_CLEAN = True
ENABLE_DEDUPLICATION = True

# -------------------------- å¤®è§†é¢‘é“åç§°æ˜ å°„ -----------------------------
CCTV_USE_MAPPING = True
CCTV_NAME_MAPPING = {
    "1": "ç»¼åˆ", "2": "è´¢ç»", "3": "ç»¼è‰º", "4": "å›½é™…", "5": "ä½“è‚²",
    "5+": "ä½“è‚²èµ›äº‹", "6": "ç”µå½±", "7": "å›½é˜²å†›äº‹", "8": "ç”µè§†å‰§",
    "9": "çºªå½•", "10": "ç§‘æ•™", "11": "æˆæ›²", "12": "ç¤¾ä¼šä¸æ³•",
    "13": "æ–°é—»", "14": "å°‘å„¿", "15": "éŸ³ä¹", "16": "å¥¥æ—åŒ¹å…‹",
    "17": "å†œä¸šå†œæ‘",
}

# -------------------------- 3TS æµ‹é€Ÿæ ¸å¿ƒé…ç½® -------------------------------
ENABLE_SPEED_TEST = True
SPEED_TEST_CONCURRENCY = 10
TS_TEST_COUNT = 3
MIN_SPEED_Mbps = 0.8
ENABLE_MIN_SPEED_FILTER = True

# -------------------------- åˆ†è¾¨ç‡ç­›é€‰ ------------------------------------
ENABLE_RESOLUTION_FILTER = True
MIN_RESOLUTION_WIDTH = 1280
MIN_RESOLUTION_HEIGHT = 720
FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION = True

# -------------------------- è´Ÿè½½æ§åˆ¶ --------------------------------------
DELAY_BETWEEN_IPS = 1.0
DELAY_AFTER_CLICK = 1.0
MAX_CHANNELS_PER_IP = 0

# -------------------------- è„šæœ¬å…¨å±€è¶…æ—¶ ----------------------------------
SCRIPT_TIMEOUT = 2400

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

IP_PATTERN = re.compile(r'^\d+\.\d+\.\d+\.\d+$')
RESOLUTION_PATTERN = re.compile(r'(\d+)x(\d+)')
CHINESE_ONLY_PATTERN = re.compile(r'[^\u4e00-\u9fff]')

def clean_chinese_only(s):
    return CHINESE_ONLY_PATTERN.sub('', s)

def normalize_cctv(name: str) -> str:
    name_lower = name.lower()
    if "cctv5+" in name_lower:
        return "CCTV-5+ä½“è‚²èµ›äº‹"
    m = re.search(r'cctv[-\s]?(\d+)', name_lower)
    if m:
        num = m.group(1)
        suf = CCTV_NAME_MAPPING.get(num, "")
        return f"CCTV-{num}{suf}"
    m = re.search(r'cetv[-\s]?(\d+)', name_lower)
    if m:
        return f"CETV-{m.group(1)}"
    return name

def build_classifier():
    rules = []
    for cat in CATEGORY_RULES:
        keywords = [kw.lower() for kw in cat["keywords"]]
        pat = re.compile('|'.join(re.escape(k) for k in keywords))
        rules.append((cat["name"], pat))
    def classify(name):
        nl = name.lower()
        for name, pat in rules:
            if pat.search(nl):
                return name
        return "å…¶ä»–é¢‘é“"
    return classify

classify_channel = build_classifier()

# ------------------------------ 3TS æµ‹é€Ÿ ------------------------------

async def fetch(session, url):
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=7)) as resp:
            if resp.status in (200, 206):
                return await resp.read()
    except:
        pass
    return None

def parse_m3u8(base_url, text):
    ts = []
    for line in text.splitlines():
        line = line.strip()
        if line.startswith("#"):
            continue
        if not line:
            continue
        ts.append(urljoin(base_url, line))
    return ts

async def test_source_3ts(url, sem):
    async with sem:
        if "m3u8" not in url.lower():
            return None, 0, False
        try:
            async with aiohttp.ClientSession() as s:
                resp = await s.get(url, timeout=aiohttp.ClientTimeout(total=10))
                if resp.status != 200:
                    return None, 0, False
                body = await resp.text()
                ts_list = parse_m3u8(url, body)
                if len(ts_list) < TS_TEST_COUNT:
                    return None, 0, False
                ts_list = ts_list[:TS_TEST_COUNT]

                total = 0
                ok = 0
                t0 = time.time()
                for u in ts_list:
                    data = await fetch(s, u)
                    if data:
                        total += len(data)
                        ok += 1
                if ok < 2:
                    return None, 0, False

                cost = time.time() - t0
                if cost <= 0:
                    return None, 0, False
                mbps = (total * 8 / 1e6) / cost

                res_ok = False
                ul = url.lower()
                if ENABLE_RESOLUTION_FILTER:
                    if "1080" in ul or "2160" in ul or "4k" in ul:
                        res_ok = True
                    elif "720" in ul and MIN_RESOLUTION_WIDTH <= 1280:
                        res_ok = True
                return url, mbps, res_ok
        except:
            return None, 0, False

async def run_speed_test(channel_map):
    sem = asyncio.Semaphore(SPEED_TEST_CONCURRENCY)
    tasks = []
    for (g, n), urls in channel_map.items():
        for u in urls:
            tasks.append((g, n, u, test_source_3ts(u, sem)))

    results = []
    for i in range(0, len(tasks), 10):
        batch = tasks[i:i+10]
        res = await asyncio.gather(*[t[3] for t in batch])
        for j, r in enumerate(res):
            g, n, u, _ = batch[j]
            url, mbps, ok_res = r
            if url and (not ENABLE_MIN_SPEED_FILTER or mbps >= MIN_SPEED_Mbps):
                results.append((g, n, url, mbps, ok_res))

    out = defaultdict(list)
    temp = defaultdict(list)
    for g, n, url, mbps, ok_res in results:
        temp[(g, n)].append((url, mbps, ok_res))

    for key, items in temp.items():
        items.sort(key=lambda x: x[1], reverse=True)
        good = [u for u, s, ok in items if ok]
        if good:
            out[key] = good[:MAX_LINKS_PER_CHANNEL]
        else:
            out[key] = [u for u, s, ok in items][:MAX_LINKS_PER_CHANNEL]
    return out

# ------------------------------ ä¸»é€»è¾‘ ------------------------------

async def _main():
    print(f"[{time.strftime('%H:%M:%S')}] ğŸš€ 3TSç²¾å‡†æµ‹é€Ÿç‰ˆå¯åŠ¨")

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-gpu",
                "--disable-dev-shm-usage",
                "--disable-extensions",
                "--disable-blink-features=AutomationControlled"
            ]
        )
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"
        )
        page = await context.new_page()

        try:
            await page.goto(TARGET_URL, timeout=PAGE_LOAD_TIMEOUT, wait_until="domcontentloaded")
            await asyncio.sleep(2)
        except:
            pass

        # ä¸å¼ºåˆ¶ç­‰å¾…IPå…ƒç´ ï¼Œé¿å…å¡æ­»
        rows = page.locator("div.ios-list-item")
        total = await rows.count()
        use = min(total, MAX_IPS) if MAX_IPS else total
        print(f"ğŸ“‹ æ‰¾åˆ° {total} ä¸ªæ¡ç›®ï¼Œä½¿ç”¨å‰ {use} ä¸ª")

        raw = []
        for i in range(use):
            try:
                row = rows.nth(i)
                title = await row.locator("div.item-title").inner_text(timeout=ACTION_WAIT_TIMEOUT)
                if not IP_PATTERN.match(title.strip()):
                    continue
                print(f"\nğŸ“Œ å¤„ç†: {title.strip()}")

                try:
                    btn = row.locator("button,div.item-title").first
                    await btn.click(timeout=ACTION_WAIT_TIMEOUT)
                    await asyncio.sleep(DELAY_AFTER_CLICK)
                except:
                    pass

                items = page.locator(".item-content")
                item_cnt = await items.count()
                for j in range(item_cnt):
                    try:
                        name = await items.nth(j).locator(".item-title").inner_text(timeout=3000)
                        link = await items.nth(j).locator(".item-subtitle").inner_text(timeout=3000)
                        name = name.strip()
                        link = link.strip()
                        if name and link:
                            norm = normalize_cctv(name)
                            cat = classify_channel(norm)
                            final = norm if cat == "å¤®è§†é¢‘é“" else clean_chinese_only(name)
                            raw.append((cat, final, link))
                    except:
                        continue

                try:
                    await page.keyboard.press("Escape")
                    await asyncio.sleep(0.5)
                except:
                    pass
            except:
                continue

        await browser.close()

    # å»é‡
    channel_map = defaultdict(list)
    seen = set()
    for g, n, u in raw:
        key = (g, n, u)
        if key in seen:
            continue
        seen.add(key)
        channel_map[(g, n)].append(u)

    # æµ‹é€Ÿ
    if ENABLE_SPEED_TEST and channel_map:
        channel_map = await run_speed_test(channel_map)

    # è¾“å‡º
    final = []
    for (g, n), urls in channel_map.items():
        for u in urls:
            final.append((g, n, u))

    grouped = defaultdict(list)
    for g, n, u in final:
        grouped[g].append((n, u))

    with open(OUTPUT_M3U_FILENAME, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for g in GROUP_ORDER:
            for n, u in grouped.get(g, []):
                f.write(f"#EXTINF:-1 group-title=\"{g}\",{n}\n{u}\n")

    with open(OUTPUT_TXT_FILENAME, "w", encoding="utf-8") as f:
        for g in GROUP_ORDER:
            lst = grouped.get(g)
            if not lst:
                continue
            f.write(f"{g},#genre#\n")
            for n, u in lst:
                f.write(f"{n},{u}\n")
            f.write("\n")

    print(f"\nğŸ‰ å®Œæˆï¼å¯¼å‡º {len(final)} æ¡ä¼˜è´¨æº")

async def main_with_timeout():
    try:
        await asyncio.wait_for(_main(), timeout=SCRIPT_TIMEOUT)
    except asyncio.TimeoutError:
        print("âš ï¸ è¶…æ—¶é€€å‡ºï¼Œä½†å·²å°½åŠ›é‡‡é›†")

if __name__ == "__main__":
    asyncio.run(main_with_timeout())
