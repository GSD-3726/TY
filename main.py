#!/usr/bin/env python3
"""
IPTV ç»„æ’­æå–å·¥å…· - ç»“æ„åˆ†æ+ç¨³å®šå®šä½+æ¥å£ä¼˜åŒ– ç»ˆæç‰ˆ
é…ç½®é¡¹å…¨æ³¨é‡Šï¼Œä¿®æ”¹åªçœ‹é¡¶éƒ¨é…ç½®åŒºå³å¯
"""

import asyncio
import os
import re
import sys
import time
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from urllib.parse import urljoin

import aiohttp
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

# ==============================================
# ================= é…ç½®åŒºï¼ˆå…¨ä¸­æ–‡è¯´æ˜ï¼‰==================
# ==============================================

# ç›®æ ‡ç½‘ç«™åœ°å€ï¼ˆè¦çˆ¬çš„ IPTV ç½‘ç«™ï¼‰
TARGET_URL = os.getenv("TARGET_URL", "https://iptv.809899.xyz")

# è¾“å‡ºæ–‡ä»¶ä¿å­˜ä½ç½®ï¼ˆé»˜è®¤è„šæœ¬æ‰€åœ¨æ–‡ä»¶å¤¹ï¼Œä¸ç”¨æ”¹ï¼‰
OUTPUT_DIR = Path(__file__).parent

# æœ€å¤šçˆ¬å¤šå°‘ä¸ªIPï¼ˆè¶Šå¤§è¶Šæ…¢ï¼Œå»ºè®® 5~20ï¼‰
MAX_IPS = int(os.getenv("MAX_IPS", "10"))

# æ— å¤´æ¨¡å¼ï¼šTrue=ä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼ŒFalse=æ˜¾ç¤ºçª—å£ï¼ˆè°ƒè¯•ç”¨ï¼‰
HEADLESS = os.getenv("HEADLESS", "true").lower() == "true"

# æµè§ˆå™¨ç±»å‹ï¼ˆé»˜è®¤chromiumï¼Œä¸ç”¨æ”¹ï¼‰
BROWSER_TYPE = os.getenv("BROWSER_TYPE", "chromium")

# é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰ï¼Œç½‘ç«™æ…¢å°±æ”¹å¤§ï¼š60000=60ç§’
PAGE_LOAD_TIMEOUT = 60000

# ç‚¹å‡»æŒ‰é’®åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢ç‚¹å¤ªå¿«é¡µé¢æ²¡ååº”
DELAY_AFTER_CLICK = 0.5

# åˆ‡æ¢ä¸‹ä¸€ä¸ªIPå‰ç­‰å¾…ç§’æ•°ï¼Œé˜²å¡é¡¿/é˜²å°
DELAY_BETWEEN_IPS = 3.0

# æ¯ä¸ªIPæœ€å¤šæå–å¤šå°‘é¢‘é“ï¼ˆ0=ä¸é™åˆ¶ï¼‰
MAX_CHANNELS_PER_IP = 0

# è„šæœ¬æœ€å¤§è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢å¡æ­»
SCRIPT_TIMEOUT = 3000

# -------------------------- æµ‹é€Ÿè®¾ç½® --------------------------
# æ˜¯å¦å¼€å¯æµ‹é€Ÿæ’åºï¼ˆTrue=æµ‹é€Ÿï¼ŒFalse=ç›´æ¥å¯¼å‡ºä¸æµ‹é€Ÿï¼‰
ENABLE_SPEED_TEST = True

# æµ‹é€Ÿå¹¶å‘æ•°ï¼ˆè¶Šå¤§è¶Šå¿«ï¼Œå»ºè®® 5~15ï¼‰
SPEED_TEST_CONCURRENCY = 10

# æœ€ä½åˆæ ¼é€Ÿåº¦ï¼ˆMbpsï¼‰ï¼Œä½äºè¿™ä¸ªå€¼ç›´æ¥ä¸¢æ‰
MIN_SPEED_FACTOR = 1.5

# æ¯ä¸ªé¢‘é“æœ€å¤šä¿ç•™å‡ æ¡é“¾æ¥ï¼ˆæŒ‰é€Ÿåº¦ä»å¿«åˆ°æ…¢å–å‰Næ¡ï¼‰
MAX_LINKS_PER_CHANNEL = 10

# -------------------------- åˆ†è¾¨ç‡ç­›é€‰ --------------------------
# æ˜¯å¦å¼€å¯åˆ†è¾¨ç‡è¿‡æ»¤
ENABLE_RESOLUTION_FILTER = True

# æœ€å°å®½åº¦ï¼š1920=1080Pï¼Œ1280=720P
MIN_RESOLUTION_WIDTH = 1920

# æœ€å°é«˜åº¦ï¼š1080=1080Pï¼Œ720=720P
MIN_RESOLUTION_HEIGHT = 1080

# æ— åˆ†è¾¨ç‡ä¿¡æ¯æ—¶ï¼Œæ˜¯å¦ä¿ç•™æœ€å¿«é“¾æ¥ï¼ˆå»ºè®®Trueï¼‰
FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION = True

# -------------------------- è¾“å‡ºæ–‡ä»¶å --------------------------
OUTPUT_M3U_FILENAME = "iptv_channels.m3u"   # ç”µè§†/ç›’å­é€šç”¨æ ¼å¼
OUTPUT_TXT_FILENAME = "iptv_channels.txt"   # æ–‡æœ¬ç›´æ’­æºæ ¼å¼

# -------------------------- é¢‘é“åˆ†ç±»è§„åˆ™ --------------------------
CATEGORY_RULES = [
    {"name": "4Kä¸“åŒº",      "keywords": ["4k"]},
    {"name": "å¤®è§†é¢‘é“",    "keywords": ["cctv", "cetv", "ä¸­å¤®"]},
    {"name": "å«è§†é¢‘é“",    "keywords": ["å«è§†", "å‡¤å‡°", "tvb", "æ¹–å—", "æµ™æ±Ÿ", "æ±Ÿè‹", "ä¸œæ–¹", "åŒ—äº¬", "æ·±åœ³", "å±±ä¸œ"]},
    {"name": "ç”µå½±é¢‘é“",    "keywords": ["ç”µå½±", "å½±é™¢", "chc"]},
    {"name": "è½®æ’­é¢‘é“",    "keywords": ["è½®æ’­"]},
    {"name": "å„¿ç«¥é¢‘é“",    "keywords": ["å°‘å„¿", "åŠ¨ç”»", "å¡é€š", "é‡‘é¹°", "å¡é…·"]},
]

# é¢‘é“åˆ†ç»„åœ¨æ–‡ä»¶é‡Œçš„æ˜¾ç¤ºé¡ºåº
GROUP_ORDER = ["å¤®è§†é¢‘é“", "å«è§†é¢‘é“", "ç”µå½±é¢‘é“", "4Kä¸“åŒº", "å„¿ç«¥é¢‘é“", "è½®æ’­é¢‘é“"]

# ==============================================
# ================= ä»¥ä¸‹ä¸ºæ ¸å¿ƒä»£ç ï¼Œä¸€èˆ¬ä¸ç”¨æ”¹ =================
# ==============================================

IP_PATTERN = re.compile(r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$')
CCTV_PATTERN = re.compile(r'(cctv)[-\s]?(\d{1,3})', re.IGNORECASE)
CETV_PATTERN = re.compile(r'(cetv)[-\s]?(\d)', re.IGNORECASE)
CHINESE_ONLY_PATTERN = re.compile(r'[^\u4e00-\u9fff]')

def build_classifier():
    compiled = []
    for rule in CATEGORY_RULES:
        if not rule["keywords"]:
            continue
        pattern = re.compile("|".join(re.escape(kw.lower()) for kw in rule["keywords"]))
        compiled.append((rule["name"], pattern))
    return lambda name: next((g for g, pat in compiled if pat.search(name.lower())), None)
classify_channel = build_classifier()

def normalize_cctv(name: str) -> str:
    name_lower = name.lower()
    if "cctv5+" in name_lower:
        return "CCTV-5+ä½“è‚²èµ›äº‹"
    m = CCTV_PATTERN.search(name_lower)
    if m:
        num = m.group(2)
        mapping = {
            "1":"ç»¼åˆ","2":"è´¢ç»","3":"ç»¼è‰º","4":"å›½é™…","5":"ä½“è‚²",
            "5+":"ä½“è‚²èµ›äº‹","6":"ç”µå½±","7":"å›½é˜²å†›äº‹","8":"ç”µè§†å‰§",
            "9":"çºªå½•","10":"ç§‘æ•™","11":"æˆæ›²","12":"ç¤¾ä¼šä¸æ³•",
            "13":"æ–°é—»","14":"å°‘å„¿","15":"éŸ³ä¹","16":"å¥¥æ—åŒ¹å…‹","17":"å†œä¸šå†œæ‘"
        }
        return f"CCTV-{num}{mapping.get(num, '')}"
    m = CETV_PATTERN.search(name_lower)
    if m:
        return f"CETV-{m.group(2)}"
    return name

def clean_chinese(name):
    return CHINESE_ONLY_PATTERN.sub('', name)

# ====================== æµ‹é€Ÿæ ¸å¿ƒ ======================
async def fetch_url(session, url, timeout):
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as r:
            if r.status == 200:
                return await r.read()
    except:
        return None

async def resolve_m3u8(session, url, timeout):
    data = await fetch_url(session, url, timeout)
    if not data:
        return None, None, []
    lines = data.decode('utf-8', 'ignore').splitlines()
    base = url[:url.rfind('/')+1] if '/' in url else url
    best_w, best_h, best_uri = 0,0,None
    i=0
    while i < len(lines):
        li = lines[i].strip()
        if li.startswith('#EXT-X-STREAM-INF:'):
            m = re.search(r'RESOLUTION=(\d+)x(\d+)', li)
            w,h = int(m.group(1)), int(m.group(2)) if m else (0,0)
            if i+1 < len(lines):
                uri = lines[i+1].strip()
                if w*h > best_w*best_h:
                    best_w,best_h,best_uri = w,h,uri
            i += 2
        else:
            i += 1
    if best_uri:
        return await resolve_m3u8(session, urljoin(base, best_uri), timeout)
    ts = []
    for li in lines:
        li = li.strip()
        if li and not li.startswith('#'):
            ts.append(urljoin(base, li))
    return best_w, best_h, ts

async def test_speed_ts(url):
    try:
        async with aiohttp.ClientSession() as s:
            w,h,ts = await resolve_m3u8(s, url, 1)
            if not ts:
                return None,None,None
            tb,tt = 0,0.0
            for u in ts[:3]:
                t0 = time.monotonic()
                d = await fetch_url(s,u,1)
                el = time.monotonic()-t0
                if d and el>0:
                    tb += len(d)
                    tt += el
            if tt == 0:
                return None,None,None
        mbps = (tb/tt)*8/1e6
        return mbps,w,h
    except:
        return None,None,None

async def test_speed_direct(url):
    try:
        async with aiohttp.ClientSession() as s:
            t0 = time.monotonic()
            tb = 0
            async with s.get(url, timeout=aiohttp.ClientTimeout(total=4)) as r:
                if r.status!=200:
                    return None
                while True:
                    c = await r.content.read(8192)
                    if not c: break
                    tb += len(c)
                    if time.monotonic()-t0 >=2: break
            el = time.monotonic()-t0
            if el <=0: return None
        return (tb/el)*8/1e6
    except:
        return None

async def task_speed(url, g, n, sem):
    async with sem:
        if '.m3u8' in url.lower():
            sp,w,h = await test_speed_ts(url)
            if sp is None or sp < MIN_SPEED_FACTOR:
                return None
            ok = True
            if ENABLE_RESOLUTION_FILTER:
                if w is None or h is None:
                    ok = FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION
                else:
                    ok = (w>=MIN_RESOLUTION_WIDTH and h>=MIN_RESOLUTION_HEIGHT)
            return (url,g,n,sp,ok)
        else:
            sp = await test_speed_direct(url)
            if sp is None or sp < MIN_SPEED_FACTOR:
                return None
            ok = FALLBACK_TO_SPEED_WHEN_NO_RESOLUTION if ENABLE_RESOLUTION_FILTER else True
            return (url,g,n,sp,ok)

async def run_speed_test(channel_map):
    total = sum(len(v) for v in channel_map.values())
    print(f"ğŸš€ æµ‹é€Ÿå¼€å§‹ï¼š{total} æ¡")
    sem = asyncio.Semaphore(SPEED_TEST_CONCURRENCY)
    tasks = [task_speed(u,g,n,sem) for (g,n),us in channel_map.items() for u in us]
    res = []
    done = 0
    printed = set()
    for coro in asyncio.as_completed(tasks):
        item = await coro
        if item:
            res.append(item)
        done += 1
        pct = int((done/len(tasks))*100)
        for s in [10,20,30,40,50,60,70,80,90,100]:
            if pct>=s and s not in printed:
                print(f"æµ‹é€Ÿè¿›åº¦ï¼š{s}%")
                printed.add(s)
    out = defaultdict(list)
    temp = defaultdict(list)
    for u,g,n,sp,ok in res:
        temp[(g,n)].append((u,sp,ok))
    for key,items in temp.items():
        items.sort(key=lambda x:x[1], reverse=True)
        good = [u for u,sp,ok in items if ok]
        if good:
            out[key] = good[:MAX_LINKS_PER_CHANNEL]
        else:
            out[key] = [u for u,sp,ok in items][:MAX_LINKS_PER_CHANNEL]
    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {sum(len(v) for v in out.values())} æ¡")
    return out

# ====================== é¡µé¢æå–ï¼ˆç»“æ„å®šä½ï¼Œä¸ä¾èµ–æ–‡å­—ï¼‰======================
async def robust_click(loc):
    try:
        await loc.scroll_into_view_if_needed(timeout=3000)
        await asyncio.sleep(0.2)
        await loc.click(force=True, timeout=5000)
        return True
    except:
        try:
            await loc.evaluate('el=>el.click()')
            return True
        except:
            return False

async def extract_one_ip(page, row):
    entries = []
    try:
        await robust_click(row.locator(".item-title").first)
        await asyncio.sleep(0.5)
        modal = page.locator(".modal-dialog").first
        await modal.wait_for(state="visible", timeout=5000)
        items = modal.locator(".item-content")
        cnt = await items.count()
        limit = cnt if MAX_CHANNELS_PER_IP==0 else min(cnt, MAX_CHANNELS_PER_IP)
        for i in range(limit):
            try:
                name = await items.nth(i).locator(".item-title").inner_text(timeout=3000)
                url = await items.nth(i).locator(".item-subtitle").inner_text(timeout=3000)
                name = name.strip()
                url = url.strip()
                if not name or not url:
                    continue
                cname = normalize_cctv(name)
                g = classify_channel(cname) or classify_channel(name)
                if not g:
                    continue
                fname = cname if g=="å¤®è§†é¢‘é“" else clean_chinese(name)
                entries.append((g, fname, url))
            except:
                continue
    except:
        pass
    return entries

async def wait_ip_list(page):
    for round in range(2):
        print(f"â³ ç­‰å¾… {round+1}/2 æ¬¡ï¼Œ30 ç§’åæ£€æŸ¥æ•°æ®")
        await asyncio.sleep(30)
        try:
            ok = await page.wait_for_function("""
                () => {
                    for(let e of document.querySelectorAll('div.item-title')){
                        if(/\\d+\\.\\d+\\.\\d+\\.\\d+/.test(e.innerText)) return true;
                    }
                    return false;
                }
            """, timeout=5000)
            if ok:
                print("âœ… IP åˆ—è¡¨å·²åŠ è½½")
                return True
        except:
            print(f"âš ï¸ ç¬¬ {round+1} æ¬¡æœªåŠ è½½åˆ°")
    print("âŒ ç»§ç»­æ‰§è¡Œ")
    return False

# ====================== ä¸»æµç¨‹ ======================
async def main_core():
    print(f"[{time.strftime('%H:%M:%S')}] å¯åŠ¨")
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=HEADLESS, args=["--no-sandbox"])
        ctx = await browser.new_context(viewport={"width":1920,"height":1080})
        page = await ctx.new_page()
        await page.goto(TARGET_URL, timeout=PAGE_LOAD_TIMEOUT, wait_until="networkidle")
        print("âœ… é¡µé¢åŠ è½½å®Œæˆ")

        # ç»“æ„å®šä½ï¼šä¸ä¾èµ–æ–‡å­—
        try:
            await page.locator("div.segment-item").nth(0).click(timeout=10000)
            await asyncio.sleep(DELAY_AFTER_CLICK)
            await page.locator("div.segment-item").nth(1).click(timeout=10000)
            await asyncio.sleep(DELAY_AFTER_CLICK)
        except:
            pass

        # ç‚¹å‡»å¼€å§‹æŒ‰é’®
        try:
            await page.locator("button").filter(has_text="å¼€å§‹æå–").first.click(timeout=10000)
            await asyncio.sleep(DELAY_AFTER_CLICK)
            print("âœ… å·²ç‚¹å‡»å¼€å§‹æå–")
        except:
            print("âš ï¸ å¼€å§‹æŒ‰é’®æœªæ‰¾åˆ°ï¼Œç»§ç»­ç­‰å¾…æ•°æ®")

        # ç­‰å¾…æ•°æ® 30s + 30s
        await wait_ip_list(page)

        # è¯»å– IP åˆ—è¡¨
        rows = page.locator("div.ios-list-item").filter(has_text="é¢‘é“:")
        total = await rows.count()
        take = min(total, MAX_IPS)
        print(f"ğŸ“‹ å…± {total} ä¸ªIPï¼Œå¤„ç†å‰ {take} ä¸ª")

        raw = []
        for i in range(take):
            ip = await rows.nth(i).locator(".item-title").inner_text()
            ip = ip.strip()
            if not IP_PATTERN.match(ip):
                continue
            print(f"ğŸ“Œ å¤„ç† {ip}")
            raw += await extract_one_ip(page, rows.nth(i))
            if i < take-1:
                await asyncio.sleep(DELAY_BETWEEN_IPS)

        # å»é‡
        channel_map = defaultdict(list)
        seen = set()
        for g,n,u in raw:
            if (g,n,u) in seen:
                continue
            seen.add((g,n,u))
            channel_map[(g,n)].append(u)
        print(f"ğŸ“Š å»é‡åé¢‘é“ï¼š{len(channel_map)}")

        # æµ‹é€Ÿ
        if ENABLE_SPEED_TEST and channel_map:
            channel_map = await run_speed_test(channel_map)

        # æ’åºè¾“å‡º
        final = []
        for (g,n),us in channel_map.items():
            for u in us:
                final.append((g,n,u))
        grouped = defaultdict(list)
        for g,n,u in final:
            grouped[g].append((n,u))

        # CCTV æŒ‰æ•°å­—æ’åº
        for g in grouped:
            if "å¤®è§†" in g:
                grouped[g].sort(key=lambda x: int(re.search(r'CCTV-(\d+)',x[0]).group(1)) if re.search(r'CCTV-(\d+)',x[0]) else 999)

        # å†™å…¥æ–‡ä»¶
        with open(OUTPUT_DIR/OUTPUT_M3U_FILENAME,'w',encoding='utf-8') as f:
            f.write("#EXTM3U\n")
            for g in GROUP_ORDER:
                for n,u in grouped.get(g,[]):
                    f.write(f'#EXTINF:-1 group-title="{g}",{n}\n{u}\n')
        with open(OUTPUT_DIR/OUTPUT_TXT_FILENAME,'w',encoding='utf-8') as f:
            for g in GROUP_ORDER:
                if g in grouped:
                    f.write(f"{g},#genre#\n")
                    for n,u in grouped[g]:
                        f.write(f"{n},{u}\n")
                    f.write("\n")

        print(f"\nğŸ‰ å®Œæˆï¼å¯¼å‡º {len(final)} æ¡é“¾æ¥")
        await browser.close()

async def main():
    try:
        await asyncio.wait_for(main_core(), SCRIPT_TIMEOUT)
    except asyncio.TimeoutError:
        print("âŒ è„šæœ¬è¶…æ—¶é€€å‡º")

if __name__ == "__main__":
    asyncio.run(main())
